{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic_pytorch_for_deeplearning_theme 9",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11i5sK_B_NTTsmZRq9kU4aqaJRSiIaD4P",
      "authorship_tag": "ABX9TyOK6LjfAQl7ul0dmfXDaygC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lhb00/basic_pytorch_for_deeplearning/blob/main/basic_pytorch_for_deeplearning_theme_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Theme 9. 성능 개선\n",
        "####(1) 과적합"
      ],
      "metadata": {
        "id": "BaR0jRh4vMFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####1. 데이터 증식"
      ],
      "metadata": {
        "id": "3IxZL6l3qAil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 딥러닝은 많은 데이터를 요구 => 추가 데이터를 확보할 수 있으면 성능 향상에 도움됨.\n",
        "# 당연히 직접 추가 데이터 모으는건 비용, 시간 때문에 쉽지는 않다. => 데이터 증식 기법을 통해 임의로 새로운 데이터를 만들어 학습 데이터에 추가\n",
        "# 데이터 증식은 통계적 기법, 단순 변형, 생성 모델 이용 등이 있으며 목적과 상황에 따라 다양한 방법 사용, 이번 예시에서는 torchvision.transforms에서 제공하는 이미지 데이터 증식 사용.\n",
        "import torchvision.transforms as tr\n",
        "import PIL\n",
        "\n",
        "transf = tr.Compose([tr.ToPILImage(), tr.RandomCrop(60), # 앞에서 나왔던 것처럼 Dataset을 정의하기 전 tranf 정의. 많은 기능들이 타입이 PIL일 경우에만 작동하므로 사용전에 데이터 타입 확인 필수!\n",
        "# RandomCrop(60)은 크기가 60X60으로 이미지 일부를 무작위로 잘라서 같은 이미지라도 매번 다른 입력 이미지로 모델에 들어갈 수 있게 함. \n",
        "# ColorJitter는 이미지의 밝기, 대비, 색조 변형 => 새로운 이미지로 만듦.\n",
        "# RandomHorizontalFlip은 이미지를 뒤집는 것. 그 외 회전, 흑백 이미지 등 다양한 기법 존재\n",
        "tr.ColorJitter(brightness=0.1,contrast=0.1, saturation=0.1,\n",
        "               hue=0.1), tr.RandomHorizontalFlip(), tr.ToTensor()])"
      ],
      "metadata": {
        "id": "c4ID-RgnvXmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2. 조기 종료"
      ],
      "metadata": {
        "id": "y93Zw-aqsI6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 불러오기\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "FSA4bFf3sFFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습, 검증, 평가 데이터 생성\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "dataset = torchvision.datasets.CIFAR10(root = '/content/drive/MyDrive/deeplearning/data', train = True,\n",
        "                                       download = True, transform = transform)\n",
        "trainset, valset = torch.utils.data.random_split(dataset, [30000, 20000]) # torch.utils.data.random_split을 통해 50000개의 dataset을 학습 데이터 30000개, 검증 데이터 20000개로 나눔.\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 32, shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=32, shuffle=False)\n",
        "testset = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/deeplearning/data', train = False,\n",
        "                                       download=True, transform = transform) # 평가 데이터는 train=False로 생성\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbxz1VcSsdJV",
        "outputId": "2ef26248-678c-4c87-be25-b1be3cb4dcbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 연산 확인\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'{device} is available.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsAcvS9Qtwc8",
        "outputId": "9bf4b8f9-934f-45e0-c363-abb2a2273b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의하기 : ResNet 이용\n",
        "import torchvision.models as models\n",
        "resnet = models.resnet18()\n",
        "resnet.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "num_ftrs = resnet.fc.in_features\n",
        "resnet.fc = nn.Sequential(nn.Dropout2d(0.5), nn.Linear(num_ftrs, 10))\n",
        "resnet = resnet.to(device)"
      ],
      "metadata": {
        "id": "aKasEUBjugQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수 및 최적화 기법\n",
        "PATH = '/content/drive/MyDrive/deeplearning/models/cifar_resnet_early.pth' # 저장 모델명 정의\n",
        "criterion = nn.CrossEntropyLoss() # 크로스 엔트로피 함수\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=1e-3) # Adam 이용"
      ],
      "metadata": {
        "id": "iWNn89PFvHhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 겅증 데이터에 대한 손실 함수값 연산 함수 정의\n",
        "def validation_loss(dataloader):\n",
        "  n = len(dataloader)\n",
        "  running_loss = 0.0\n",
        "  with torch.no_grad(): # 평가만 하므로 requires_grad 비활성화\n",
        "    resnet.eval() # 평가 시 정규화 기법들이 작동하지 않도록 eval 모드로 설정\n",
        "    for data in dataloader:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      outputs = resnet(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      running_loss+=loss.item()\n",
        "  resnet.train() # 모델을 train 모드로 변경\n",
        "  return running_loss / n"
      ],
      "metadata": {
        "id": "9qR8DEqbvaxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습하기\n",
        "train_loss_list = [] # 손실 함수 그래프를 그리기 위해 학습/검증 데이터에 대한 손실 함수값을 각각 담을 수 있는 빈 리스트 생성\n",
        "val_loss_list = []\n",
        "n = len(trainloader) # 매 에포크 마다 평균 손실 함수 값을 구하기 위해 n 설정\n",
        "early_stopping_loss = 1 # 가장 낮은 검증 손실 함수값에 해당하는 모델을 저장하기 위해 손실 함수값 초기 기준을 1로 한다.\n",
        "for epoch in range(51):\n",
        "  running_loss = 0.0\n",
        "  for data in trainloader: # 배치 데이터를 받아 학습 진행\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = resnet(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  train_loss = running_loss / n # 배치 학습이 한 번 완료될 때마다 평균 손실 함수값 저장\n",
        "  train_loss_list.append(train_loss)\n",
        "  val_loss = validation_loss(valloader) # 검증 데이터에 대한 손실 함수값 저장\n",
        "  val_loss_list.append(val_loss)\n",
        "  print('[%d] train loss: %.3f, validation loss: %.3f' %(epoch + 1, train_loss, val_loss)) # 현재 에포크의 평가, 검증 손실 함수값 출력\n",
        "  if val_loss < early_stopping_loss: # 만약 현재 검증 손실 함수값 < 기준 => 모델 저장 & 현재의 에포크, 평가, 검증 손실 함수값 저장\n",
        "    torch.save(resnet.state_dict(), PATH)\n",
        "    early_stopping_train_loss=train_loss\n",
        "    early_stopping_val_loss = val_loss\n",
        "    early_stopping_epoch = epoch\n",
        "\n",
        "print('Final pretrained model >> [%d] train loss: %.3f, validation loss: %.3f' %(early_stopping_epoch+1, early_stopping_train_loss, early_stopping_val_loss))\n",
        "# 학습 완료 시 조기 종료한 에포크 & 손실 함수값들 출력. 결과를 보면 번째 학습 시검증 손실 함수값이 가장 작다."
      ],
      "metadata": {
        "id": "39Hubg91xC52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cde0a70-3c76-4c92-c136-b90f9c21ec5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] train loss: 0.371, validation loss: 0.791\n",
            "[2] train loss: 0.398, validation loss: 0.761\n",
            "[3] train loss: 0.399, validation loss: 0.746\n",
            "[4] train loss: 0.392, validation loss: 0.752\n",
            "[5] train loss: 0.378, validation loss: 0.735\n",
            "[6] train loss: 0.357, validation loss: 0.732\n",
            "[7] train loss: 0.338, validation loss: 0.741\n",
            "[8] train loss: 0.322, validation loss: 0.742\n",
            "[9] train loss: 0.312, validation loss: 0.744\n",
            "[10] train loss: 0.298, validation loss: 0.771\n",
            "[11] train loss: 0.284, validation loss: 0.786\n",
            "[12] train loss: 0.279, validation loss: 0.767\n",
            "[13] train loss: 0.275, validation loss: 0.853\n",
            "[14] train loss: 0.266, validation loss: 0.815\n",
            "[15] train loss: 0.257, validation loss: 0.808\n",
            "[16] train loss: 0.264, validation loss: 0.799\n",
            "[17] train loss: 0.259, validation loss: 0.825\n",
            "[18] train loss: 0.243, validation loss: 0.790\n",
            "[19] train loss: 0.242, validation loss: 0.863\n",
            "[20] train loss: 0.250, validation loss: 0.848\n",
            "[21] train loss: 0.239, validation loss: 0.831\n",
            "[22] train loss: 0.248, validation loss: 0.835\n",
            "[23] train loss: 0.236, validation loss: 0.843\n",
            "[24] train loss: 0.241, validation loss: 0.806\n",
            "[25] train loss: 0.230, validation loss: 0.840\n",
            "[26] train loss: 0.237, validation loss: 0.833\n",
            "[27] train loss: 0.230, validation loss: 0.872\n",
            "[28] train loss: 0.231, validation loss: 0.858\n",
            "[29] train loss: 0.229, validation loss: 0.889\n",
            "[30] train loss: 0.232, validation loss: 0.897\n",
            "[31] train loss: 0.230, validation loss: 0.829\n",
            "[32] train loss: 0.217, validation loss: 0.860\n",
            "[33] train loss: 0.229, validation loss: 0.897\n",
            "[34] train loss: 0.224, validation loss: 0.861\n",
            "[35] train loss: 0.224, validation loss: 0.820\n",
            "[36] train loss: 0.219, validation loss: 0.853\n",
            "[37] train loss: 0.224, validation loss: 0.825\n",
            "[38] train loss: 0.217, validation loss: 0.858\n",
            "[39] train loss: 0.218, validation loss: 0.870\n",
            "[40] train loss: 0.227, validation loss: 0.820\n",
            "[41] train loss: 0.208, validation loss: 0.888\n",
            "[42] train loss: 0.233, validation loss: 0.887\n",
            "[43] train loss: 0.215, validation loss: 0.885\n",
            "[44] train loss: 0.216, validation loss: 0.956\n",
            "[45] train loss: 0.223, validation loss: 0.871\n",
            "[46] train loss: 0.212, validation loss: 0.870\n",
            "[47] train loss: 0.214, validation loss: 0.890\n",
            "[48] train loss: 0.217, validation loss: 0.910\n",
            "[49] train loss: 0.210, validation loss: 0.901\n",
            "[50] train loss: 0.208, validation loss: 0.891\n",
            "[51] train loss: 0.224, validation loss: 0.861\n",
            "Final pretrained model >> [51] train loss: 0.224, validation loss: 0.861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수값 그래프 그리기\n",
        "plt.plot(train_loss_list)\n",
        "plt.plot(val_loss_list)\n",
        "plt.legend(['train','validation'])\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "06lSYX2J7TjN",
        "outputId": "d67f7e5e-3f58-4231-e9ae-b6c618f6dda0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####3. L2 정규화"
      ],
      "metadata": {
        "id": "DyK6GNxK7hbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# L2 정규화는 경계를 만들어 학습 데이터에서의 최적 변수 w*에 도달하지 못하게 함. 경계 안에서만 변수를 최적화 하게함.\n",
        "# 따라서 모델 최적화된다면 v*로 수렴\n",
        "# Adam 사용 시 weight_decay에 L2 패널티 값을 입력하고 L2 정규화 활성화, 패널티 값이 클수록 제약조건이 강해지고 0이면 정규화를 사용하지 않음 => 문제마다 적절한 값 입력 필수\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=1e-3, weight_decay=1e-3)"
      ],
      "metadata": {
        "id": "nk0LMMDo7iuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####4. 드롭아웃"
      ],
      "metadata": {
        "id": "C-JK1M5w8Av9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인공 신경망에서 무작위로 일정한 비율의 노드를 제외, 학습하는 방법을 드롭아웃이라함.\n",
        "# => 한 번 변수 갱신이 일어날 때마다 제외된 노드와 관련 있는 변수는 갱신 X => 학습 데이터에 대한 모델 최적화 억제 가능!\n",
        "# 드롭아웃의 세팅 방법 : 출력층은 예측값이 나오는 단계이므로 적용 X => 출력층의 노드는 절대 지우지 않음, 원하는 층에만 적용 가능 & 제외 비율도 조정 가능\n",
        "# 학습이 반복될 때마다 제외할 노드를 무작위로 선택, 학습에서 과적합 방지 & 시험 데이터를 이용하는 것과 같은 평가 단계에서는 드롭아웃 적용 X, 원래 전체 모델 사용(.eval()) 함수 선언\n",
        "class Regressor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(13,50)\n",
        "    self.fc2 = nn.Linear(50,1)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.dropout(F.relu(self.fc1(x)))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    return x\n",
        "# nn.Dropout(0.5)은 해당 노드에 50%를 선택해 노드를 사용하지 않겠다는 뜻, F.relu(self.fc1(x))의 노드는 50개이므로 25개 노드 비활성화.\n",
        "# 또 다른 표현으로는 torch.nn.functional.dropout(input, p=0.5, training=True)"
      ],
      "metadata": {
        "id": "LVNmoSsY8CKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####6. 교란 라벨"
      ],
      "metadata": {
        "id": "Nb2cd3-39Sl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 교란 라벨은 분류 문제에서 일정 비율만큼 잘못된 라벨을 의도적으로 만들어 학습을 방해하는 방법.\n",
        "# 단순하지만 분류 문제에서의 과적합을 효과적으로 막을 수 있다.\n",
        "# 교란 라벨 정의\n",
        "class DisturbLabel(torch.nn.Module): # DisturbLabel 클래스를 만든다.\n",
        "  def __init__(self, alpha, num_classes): # 교란 라벨 비율(0~100)과 클래스 수를 받는다.\n",
        "    super(DisturbLabel, self).__init__()\n",
        "    self.alpha = alpha\n",
        "    self.C = num_classes\n",
        "    self.p_c = (1-((self.C - 1) / self.C) * (alpha/100)) # 실제 라벨을 뽑을 확률을 self.p_c로 부여, 나머지는 self.p_i로 부여\n",
        "    self.p_i = (1-self.p_c)/(self.C-1) # ex. 클래스 수가 10, 교란 라벨 비율이 30%라면 self.p_c = 73/100, self.p_i=3/100, 실제 라벨이 5라면 뽑힐 확률 분포 = (3/100, 3/100, 3/100, 3/100, 3/100, 73/100, 3/100, 3/100, 3/100, 3/100)\n",
        "  def forward(self,y):\n",
        "    y_tensor = y.type(torch.LongTensor).view(-1,1) # 앞서 언급한 라벨이 뽑힐 확률 분포를 만들어줌.\n",
        "    depth = self.C\n",
        "    y_one_hot = torch.ones(y_tensor.size()[0], depth) * self.p_i\n",
        "    y_one_hot.scatter_(1, y_tensor, self.p_c)\n",
        "    y_one_hot = y_one_hot.view(*(tuple(y.shape) + (-1,))) # 해당 확률을 이용, Multinoulli 분포를 통해 샘플을 뽑음\n",
        "    distribution = torch.distributions.OneHotCategorical(y_one_hot)\n",
        "    y_disturbed = distribution.sample()\n",
        "    y_disturbed = y_disturbed.max(dim=1)[1] # 10개의 원소 중 가장 큰 값의 라벨을 뽑음. 확률 분포를 이용해 교란 라벨을 만들기에, 비율이 30%라고 해서 반드시 미니 배치의 30%가 교란 라벨인 것은 아님.\n",
        "    return y_disturbed"
      ],
      "metadata": {
        "id": "Ma8FhYxt9EMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 교란 라벨 선언 및 적용\n",
        "loss_ = []\n",
        "n = len(trainloader)\n",
        "disturblabels = DisturbLabel(alpha=30, num_classes=10) # 학습 전 DisturbLabel 선언\n",
        "for epoch in range(50):\n",
        "  running_loss = 0.0\n",
        "  for data in trainloader:\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = resnet(inputs)\n",
        "    labels = disturblabels(labels).to(device) # 손실 함수 계산 이전에 교란 라벨 생성, 거짓 라벨과 함께 손실 함수를 계산하게 함.\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss+=loss.item()\n",
        "\n",
        "  loss_.append(running_loss / n)\n",
        "  print('[%d] loss: %.3f' %(epoch + 1, running_loss / n))\n",
        "\n",
        "torch.save(resnet.state_dict(), PATH)\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHJU-lbaA5_h",
        "outputId": "daae7e30-6e4a-4ed8-e92e-601bc761a447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] loss: 2.031\n",
            "[2] loss: 1.816\n",
            "[3] loss: 1.736\n",
            "[4] loss: 1.648\n",
            "[5] loss: 1.613\n",
            "[6] loss: 1.549\n",
            "[7] loss: 1.509\n",
            "[8] loss: 1.473\n",
            "[9] loss: 1.442\n",
            "[10] loss: 1.414\n",
            "[11] loss: 1.394\n",
            "[12] loss: 1.372\n",
            "[13] loss: 1.340\n",
            "[14] loss: 1.328\n",
            "[15] loss: 1.313\n",
            "[16] loss: 1.317\n",
            "[17] loss: 1.286\n",
            "[18] loss: 1.280\n",
            "[19] loss: 1.284\n",
            "[20] loss: 1.255\n",
            "[21] loss: 1.274\n",
            "[22] loss: 1.258\n",
            "[23] loss: 1.254\n",
            "[24] loss: 1.249\n",
            "[25] loss: 1.238\n",
            "[26] loss: 1.257\n",
            "[27] loss: 1.247\n",
            "[28] loss: 1.236\n",
            "[29] loss: 1.245\n",
            "[30] loss: 1.249\n",
            "[31] loss: 1.243\n",
            "[32] loss: 1.230\n",
            "[33] loss: 1.242\n",
            "[34] loss: 1.230\n",
            "[35] loss: 1.233\n",
            "[36] loss: 1.238\n",
            "[37] loss: 1.230\n",
            "[38] loss: 1.233\n",
            "[39] loss: 1.212\n",
            "[40] loss: 1.238\n",
            "[41] loss: 1.246\n",
            "[42] loss: 1.234\n",
            "[43] loss: 1.225\n",
            "[44] loss: 1.226\n",
            "[45] loss: 1.210\n",
            "[46] loss: 1.220\n",
            "[47] loss: 1.237\n",
            "[48] loss: 1.227\n",
            "[49] loss: 1.217\n",
            "[50] loss: 1.207\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####7. 교란 값"
      ],
      "metadata": {
        "id": "O9j9KhD9CYhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # 데이터프레임 형태를 다룰 수 있는 라이브러리\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split # 전체 데이터를 학습 데이터와 평가 데이터로 나눈다.\n",
        "\n",
        "# ANN\n",
        "import torch\n",
        "from torch import nn, optim # torch 내의 세부적인 기능을 불러온다. (신경망 기술, 손실함수, 최적화 방법 등)\n",
        "from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n",
        "import torch.nn.functional as F # torch 내의 세부적인 기능을 불러온다. (신경망 기술 등)\n",
        "\n",
        "# Loss\n",
        "from sklearn.metrics import mean_squared_error # Regression 문제의 평가를 위해 MSE(Mean Squared Error)를 불러온다.\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt # 시각화 도구"
      ],
      "metadata": {
        "id": "iV7T40BFVeHT"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Regressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(13, 50)\n",
        "        self.fc2 = nn.Linear(50, 30)\n",
        "        self.fc3 = nn.Linear(30, 1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = F.relu(self.fc3(x)) \n",
        "      \n",
        "        return x"
      ],
      "metadata": {
        "id": "hzCKsPreyBXD"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Regressor()\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-7)"
      ],
      "metadata": {
        "id": "h4suR6yLDZ_0"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 교란 값은 회귀 문제에서 일정 비율만큼 라벨에 노이즈 주입, 학습 데이터에 대해 최적화를 방해하는 방법\n",
        "# 아주 간단, 어떠한 모델에도 적용 할 수 있다는 것이 큰 장점\n",
        "# 노이즈 생성\n",
        "def noise_generator(x, alpha): # 타깃값과 노이즈 비율(0~1을 받음)\n",
        "    noise = torch.normal(0, 1e-2, size=(len(x), 1)) # 임의로 정한 정규분포에 따른 노이즈 생성\n",
        "    noise[torch.randint(0, len(x), (int(len(x)*(1-alpha)),))] = 0 # 노이즈 타깃이 아닌 값은 노이즈를 0으로함.\n",
        "\n",
        "    return noise"
      ],
      "metadata": {
        "id": "xGvKE5FrCXK1"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_ = [] \n",
        "n = len(trainloader)\n",
        "\n",
        "for epoch in range(400): \n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for data in trainloader: \n",
        "        inputs, values = data \n",
        "       \n",
        "        optimizer.zero_grad() \n",
        "\n",
        "        outputs = model(inputs) \n",
        "        values = values + noise_generator(values, 0.3)\n",
        "        loss = criterion(outputs, values)\n",
        "\"\"\"\n",
        "이하 생략, 앞과 과정이 동일함.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JbRZ0ZgcXINo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####8. 라벨 스무딩"
      ],
      "metadata": {
        "id": "MeQXy-JkDraq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이토치에서 제공하는 크로스 엔트로피 함수 nn.CrossEntropyLoss()는 실제 라벨의 원 핫 벡터를 입력으로 못받음. => 라벨 스무딩 적용 시 원 핫 벡터를 사용할 수 있도록 별도로 손실 함수 생성해야함.\n",
        "# 라벨 스무딩 정의 및 선언\n",
        "class LabelSmoothingLoss(nn.Module):\n",
        "  def __init__(self, classes, smoothing=0.0, dim = -1):\n",
        "    super(LabelSmoothingLoss, self).__init__()\n",
        "    self.confidence = 1.0 - smoothing\n",
        "    self.smoothing = smoothing\n",
        "    self.cls = classes\n",
        "    self.dim = dim\n",
        "\n",
        "  def forward(self, pred, target):\n",
        "    pred = pred.log_softmax(dim=self.dim) # Cross Entropy 부분의 log softmax를 미리 계산 \n",
        "    with torch.no_grad():\n",
        "      true_dist = torch.zeros_like(pred) # 예측값과 동일한 크기의 영텐서 생성\n",
        "      true_dist.fill(self.smoothing / (self.cls - 1)) # alpha(K-1) 생성 (alpha/K 가능)\n",
        "      true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) # (1-alpha)y + alpha(K-1) 수행.\n",
        "    return torch.mean(torch.sum(-true_dist * pred, dim=self.dim)) # pred를 함께 사용, Cross Entropy Loss 함수 계산\n",
        "  "
      ],
      "metadata": {
        "id": "o1nfBWf1DqVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = LabelSmoothingLoss(classes=10, smoothing=0.2) # Cifar10 데이터 사용 시 클래스는 10개로 지정, 적절한 스무딩 비율을 넣어 nn.CrosEntropyLoss() 대신 LabelSmoothingLoss로 criterion 선언"
      ],
      "metadata": {
        "id": "HoJd7RHUFMLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####(2) 데이터 불균형"
      ],
      "metadata": {
        "id": "d4bclRznM4fN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####1. 가중 무작위 샘플링"
      ],
      "metadata": {
        "id": "QR2FhzsdM9BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 주어진 데이터가 불균형 데이터라도 우리는 미니 배치를 균형 데이터로 뽑을 수 있음.\n",
        "# => 배치를 만들 때마다 각 클래스의 동일한 개수를 뽑는다면 한 번 학습 시 균형 데이터를 사용하게 됨.\n",
        "# 이 방법을 가중 무작위 샘플링이라한다.\n",
        "# 가중치 함수 만들기\n",
        "import numpy as np\n",
        "def make_weights(labels, nclasses): # 라벨과 클래스 수를 받음.\n",
        "  labels = np.array(labels) # 리스트 타입을 넘파이 배열로 바꿈.\n",
        "  weight_list=[]\n",
        "  for cls in range(nclasses): # 각 클래스마다 라벨의 개수를 셈\n",
        "    idx = np.where(labels == cls)[0]\n",
        "    count = len(idx)\n",
        "    weight = 1/count # 라벨이 뽑힐 가중치를 1/count로 동일하게 해당 라벨 전체에 할당\n",
        "    weights = [weight] * count\n",
        "    weight_list+=weights # 데이터를 불러올 때 ImageFolder를 사용할 경우 라벨이 0부터 N 까지 차례대로 나열되어 있음. => 각 클래스의 가중치를 일렬로 이어줌.\n",
        "  return weight_list"
      ],
      "metadata": {
        "id": "LUW391imM7Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터 불러오기\n",
        "# 이 예시에서는 클래스가 2개인 이미지 데이터를 불러온다.(각각 14, 4개)\n",
        "transf = tr.Compose([tr.Resize((16,16)),tr.ToTensor()])\n",
        "trainset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/deeplearning/class', transform=transf)"
      ],
      "metadata": {
        "id": "dNP5H2NvNwWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 생성\n",
        "weights = make_weights(trainset.targets, len(trainset.classes)) # 가중치를 생성 후 텐서로 변환\n",
        "weights = torch.DoubleTensor(weights)\n",
        "print(weights)\n",
        "# 가중치 텐서를 보면 모든 데이터에 대한 각각의 가중치가 있음을 알 수 있음. & 각 클래스의 가중치의 합이 1로 같음\n",
        "# => 하나의 클래스를 뽑을 확률이 같다는 의미(파이토치에서는 weights의 전체 합이 1일 필요 X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDlYTAd-rEgR",
        "outputId": "83642b2c-cf47-4076-9a94-7dfb6da4c494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2500, 0.2500, 0.2500, 0.2500, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714,\n",
            "        0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더 생성\n",
        "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights)) # 파이토치에서 제공하는 WeightedRandomSampler를 사용, 배치를 불러올 때 자동으로 클래스에 대한 균일 분포를 갖는 배치를 만들 수 있다.\n",
        "trainloader_wrs = DataLoader(trainset, batch_size=6, sampler=sampler) # DataLoader에 sampler를 추가, 데이터 준비를 완료함.\n",
        "trainloader_rs = DataLoader(trainset, batch_size=6, shuffle=True) # 가중 무작위 샘플링과 무작위 샘플링의 비교를 위해 무작위 샘플링을 하는 DataLoader를 추가적으로 만듦."
      ],
      "metadata": {
        "id": "66Ywdqj9regj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중 무작위 샘플링vs무작위 샘플링\n",
        "# 배치 사이즈를 6개로 한 경우 2개의 클래스가 각각 3개로 들어오는 것이 이상적, But, 확률적으로 데이터를 뽑기 때문에 반드시 3개씩 뽑히지 않음 => 그래도 무작위 샘플링 보다는 균형 잡힌 데이터\n",
        "for epoch in range(5):\n",
        "  for data in trainloader_wrs:\n",
        "    print(data[1])\n",
        "# 현재 데이터는 클래스 1이 클래스 0보다 3.5배 많음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taqadVxDr_wn",
        "outputId": "a7a1eb9f-6347-413b-975c-faec1a29600d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 1, 1, 1, 1])\n",
            "tensor([0, 1, 1, 0, 1, 0])\n",
            "tensor([0, 1, 1, 1, 0, 1])\n",
            "tensor([1, 1, 1, 0, 0, 0])\n",
            "tensor([1, 0, 0, 1, 0, 0])\n",
            "tensor([1, 1, 0, 0, 0, 0])\n",
            "tensor([0, 0, 1, 1, 1, 0])\n",
            "tensor([1, 0, 0, 0, 1, 1])\n",
            "tensor([1, 1, 1, 0, 1, 0])\n",
            "tensor([1, 1, 1, 1, 0, 0])\n",
            "tensor([0, 0, 0, 0, 1, 0])\n",
            "tensor([0, 1, 1, 1, 1, 1])\n",
            "tensor([1, 0, 0, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 1])\n",
            "tensor([1, 0, 1, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다음과 같이 무작위로 뽑았을 경우 클래스 1이 배치 전체를 차지함을 알 수 있음.\n",
        "for epoch in range(5):\n",
        "  for data in trainloader_rs:\n",
        "    print(data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oobz5mqasXKf",
        "outputId": "3203625c-93c0-40cf-8875-af8aca9ca9af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 0, 1, 1])\n",
            "tensor([0, 1, 1, 0, 1, 1])\n",
            "tensor([1, 1, 0, 1, 1, 1])\n",
            "tensor([0, 0, 1, 0, 1, 1])\n",
            "tensor([0, 1, 1, 1, 1, 1])\n",
            "tensor([1, 1, 1, 1, 1, 1])\n",
            "tensor([1, 1, 1, 0, 1, 0])\n",
            "tensor([1, 1, 1, 1, 1, 1])\n",
            "tensor([1, 1, 0, 0, 1, 1])\n",
            "tensor([1, 1, 1, 0, 1, 1])\n",
            "tensor([0, 1, 1, 1, 1, 1])\n",
            "tensor([1, 1, 0, 1, 0, 1])\n",
            "tensor([1, 1, 1, 1, 0, 1])\n",
            "tensor([1, 1, 1, 1, 0, 1])\n",
            "tensor([1, 1, 1, 0, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2. 가중 손실 함수"
      ],
      "metadata": {
        "id": "vBF4SG0zsmjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이토치의 nn.CrossEntropyLoss는 가중 손실 함수 제공 => 미리 정의된 weight를 입력하면 쉽게 구현 가능.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_ins = [40, 45, 30, 62, 70, 153, 395, 46, 75, 194] # ex. 10개 클래스의 각각 이미지 개수를 알고 있다고 가정. 가중 손실 함수는 데이터가 적은 클래스에 큰 가중치를 부여, 업데이트 균형을 맞추려는 의도를 지님.\n",
        "weights = [1-(x/sum(num_ins)) for x in num_ins] # 이 예시에서는 각 클래스의 확률 x/sum(num_ins)를 구한 뒤 1에서 뺀 값을 가중치로 사용\n",
        "class_weights = torch.FloatTensor(weights).to(device) # 다음 텐서로 변환된 가중치를 nn.CrossEntropyLoss에 넣어줌.\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)"
      ],
      "metadata": {
        "id": "o4oxcc7usoV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####3. 혼동 행렬"
      ],
      "metadata": {
        "id": "qCgeaHp7tlsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 혼동 행렬 : 데이터 불균형의 직접적인 해결책 X, But 결과를 행렬화하여 각 클래스의 분포, 정확도를 확인하여 불균형 데이터로 예측 쏠림 현상 인지 가능. 다양한 결과와 해석에 사용\n",
        "from sklearn.metrics import confusion_matrix # 관련 라이브러리 불러옴.\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "actual = [1,1,1,0,0,0,0,0,2,2,2,2,2,2,2,2] # 실제값과 예측값을 알고 있다고 가정\n",
        "prediction = [1,2,2,0,2,2,1,2,0,1,0,2,2,2,2,2]\n",
        "c_mat = confusion_matrix(actual, prediction) # 혼동 행렬 틀을 만들어 플로팅\n",
        "plt.figure(figsize = (8,6))\n",
        "sns.heatmap(c_mat, annot=True, fmt=\"d\", cmap='Blues', linewidths=.5)\n",
        "b, t = plt.ylim() # 이때 그냥 plt.ylim()을 사용할 경우 버전에 따라 위, 아래가 잘려서 그래프가 출력 될 수 있으므로 위, 아래 범위를 0.5씩 확보\n",
        "b+=0.5\n",
        "t-=0.5\n",
        "plt.ylim(b,t)\n",
        "plt.savefig('confusion_matrix.png')\n",
        "plt.show()\n",
        "# 결과 확인 => 클래스 0, 1이 클래스2로 많이 예측된걸 확인 가능, 즉 모델 변수가 데이터가 가장 많은 클래스2로 치우쳐 있다는 뜻."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "GcsijafTtohn",
        "outputId": "2c119b76-371e-4f7c-e0fd-27191a0bdc0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####(3) 전이 학습"
      ],
      "metadata": {
        "id": "F2xAoaIovYbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####1. 사전 학습 모델"
      ],
      "metadata": {
        "id": "UiC6aYwuvdCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 앞에서 봤듯이 torchvision.models as models를 이용, ImageNet 데이터로 학습된 사전 학습 모델을 쉽게 사용 가능.\n",
        "# 또 앞에서 봤듯이 모델 내부의 변수명 확인 & 모델 일부 수정 가능\n",
        "import torchvision.models as models\n",
        "alexnet = models.alexnet().to(device)\n",
        "resnet18 = models.resnet18().to(device)\n",
        "vgg16 = models.vgg16().to(device)\n",
        "densenet = models.densenet161().to(device)\n",
        "inception = models.inception_v3().to(device)\n",
        "googlenet = models.googlenet().to(device)\n",
        "shufflenet = models.shufflenet_v2_x1_0().to(device)\n",
        "mobilenet_v2 = models.mobilenet_v2().to(device)\n",
        "resnext50_32x4d = models.resnext50_32x4d().to(device)\n",
        "wide_resnet50_2 = models.wide_resnet50_2().to(device)\n",
        "mnasnet = models.mnasnet1_0().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqaAKPTKvZxg",
        "outputId": "83c0a60d-4257-4707-baf4-b2f8bebd4483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:47: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/googlenet.py:51: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR10을 위한 ResNet18 불러오기\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1) # 불러온 모델: 사이즈가 CIFAR10보다 큰, ImageNet 데이터가 맞춰진 모델 => 원래 첫번째 합성곱 층의 필터 사이즈가 7X7이라서 CIFAR10 데이터에는 큰 사이즈임. => 3X3 vlfxjfh qusrud\n",
        "num_ftrs = model.fc.in_features # 원래 모델의 마지막 출력 노드가 1000이기 때문에 우리 데이터에 맞춰 10개로 변경\n",
        "model.fc = nn.Linear(num_ftrs, 10)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW3YMrPJwXWm",
        "outputId": "ee77f288-010a-4781-9cd8-c26beb01bade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2. 모델 프리징"
      ],
      "metadata": {
        "id": "uQuGNQDIzNsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 프리징 : 기존의 일부 모델 변수들을 그대로 사용하기 위해 업데이트가 되지 않도록 하는 방법\n",
        "# => 사전 학습된 변수를 그대로 유지 가능, 학습 속도와 정확도 향상, 다른 모델과 붙여 다른 구조를 만들 수 있다.\n",
        "# CNN에서는 피쳐 추출 부분은 프리징 시키고 분류 파트만 학습을 진행하기도 함. But, 모델을 튜닝하고 프리징하는데 정답 따윈 없으니 다양한 시도 하자.\n",
        "# 모델 불러오기\n",
        "model = torchvision.models.alexnet(pretrained=True) # 모델을 불러온 후 출력 레이어의 노드 = 클래스 수로 설정\n",
        "num_ftrs = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_ftrs,10)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSC4rBndxIpo",
        "outputId": "5b5b6e69-ec61-4144-f498-29bc9d4bdeff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 파라미터명 확인\n",
        "for i, (name, param) in enumerate(model.named_parameters()): # model.named_parameters()를 이용, 가중치와 편향 목록 출력 가능.\n",
        "  print(i, name) # 리스트의 차례를 알 수 있도록 i와 같이 출력. 출력 결과를 보면 0~9번째는 합성곱 층에 대한 가중치 & 편향, 10번 이후는 분류기의 가중치와 편향."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUiBij9xz6V0",
        "outputId": "209668dd-1797-4d7e-9aff-526959d33bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 features.0.weight\n",
            "1 features.0.bias\n",
            "2 features.3.weight\n",
            "3 features.3.bias\n",
            "4 features.6.weight\n",
            "5 features.6.bias\n",
            "6 features.8.weight\n",
            "7 features.8.bias\n",
            "8 features.10.weight\n",
            "9 features.10.bias\n",
            "10 classifier.1.weight\n",
            "11 classifier.1.bias\n",
            "12 classifier.4.weight\n",
            "13 classifier.4.bias\n",
            "14 classifier.6.weight\n",
            "15 classifier.6.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수 프리징\n",
        "for i, (name, param) in enumerate(model.named_parameters()):\n",
        "  param.requires_grad = False # 파라미터의 requires_grad를 False로 하여 학습 시 업데이트 되지 않도록 함.\n",
        "  if i ==9: # if문을 통해 합성곱 층에 대한 가중치와 편향(9번까지)만 프리징이 되면 for문을 멈춤.\n",
        "    print('end')\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpFWNcZJ0OUJ",
        "outputId": "28d6be05-19d0-4eb0-8e1e-a6108162a7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_list = [0,3,6,8,10]\n",
        "c_list = [1,4,6]\n",
        "for i in f_list:\n",
        "  print(model.features[i].weight.requires_grad)\n",
        "  print(model.features[i].bias.requires_grad)\n",
        "for j in c_list:\n",
        "  print(model.classifier[j].weight.requires_grad)\n",
        "  print(model.classifier[j].bias.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DJum-yq0keJ",
        "outputId": "03361c6a-b122-450f-f9b9-4d95f3bb5622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####(4) 준지도 학습"
      ],
      "metadata": {
        "id": "4vXcWlOR18cJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####1. 의사 라벨링"
      ],
      "metadata": {
        "id": "VUlx7Cej1-bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 의사 라벨링 : 준지도 학습 중 가장 기본적으로 사용되는 방법.\n",
        "# 우리가 라벨이 없는 데이터를 지도 학습에 사용시에는 라벨을 달아 줘야함. => 이미 학습된 모델을 이용하여 라벨링이 되지 않는 데이터를 예측, 그 예측값을 기준으로 라벨링 하여 기존의 학습 데이터와 함께 학습에 사용하는 방법이 의사 라벨링.\n",
        "# 주의점: 예측값을 라벨로 이용, 라벨에 대한 불확실성 존재 => 무분별한 사용 자제 & 다양한 형태로 모델 구현 가능. 우리는 2가지 의사 라벨링 방법을 정의하여 성능 향상 달성할 것임.\n",
        "# 라이브러리 불러오기\n",
        "import torch # 넘파이 및 파이토치 라이브러리 불러오기\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm # for문의 진행 상황을 알려주는 라이브러리"
      ],
      "metadata": {
        "id": "A3Hl8Hn-1_zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 연산 정의\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xprLuhbb2rH5",
        "outputId": "026cf5d3-d05c-4dce-de4a-783cd55c8e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 세트 정의\n",
        "class MyDataset(Dataset): # 이전의 내용을 바탕으로 데이터 세트 클래스 정의\n",
        "  def __init__(self, x_data, y_data, transform=None):\n",
        "    self.x_data = x_data\n",
        "    self.y_data = y_data\n",
        "    self.transform = transform\n",
        "    self.len = len(y_data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample = self.x_data[index], self.y_data[index]\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len"
      ],
      "metadata": {
        "id": "KRkCSBSG2zgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 정의\n",
        "class TrainTransform: # 마찬가지로 이전의 내용을 바탕으로 학습 데이터 대한 전처리 정의\n",
        "  def __call__(self, sample):\n",
        "    inputs, labels = sample\n",
        "    transf = transforms.Compose([transforms.ToPILImage(),\n",
        "                                 transforms.RandomHorizontalFlip(), transforms.ToTensor()])\n",
        "    final_output = transf(inputs)\n",
        "    return final_output, labels"
      ],
      "metadata": {
        "id": "j9BwB5JC3WA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 세트 나누기\n",
        "# 실험을 위해 각 클래스의 이미지 개수가 같도로 데이터를 나눈다.\n",
        "def balanced_subset(data, labels, num_cls, num_data): # 데이터, 라벨, 클래스 수, 나눠지는 목표 데이터 개수를 받음.\n",
        "  num_data_per_class = num_data // num_cls # 각 클래스의 데이터 개수 정의\n",
        "  data1 = torch.tensor([], dtype=torch.float) # 나눠지는 두 개의 세트를 저장하기 위해 데이터, 라벨 텐서를 각각 2개 정의\n",
        "  data2 = torch.tensor([], dtype=torch.float)\n",
        "  labels1 = torch.tensor([], dtype=torch.long)\n",
        "  labels2 = torch.tensor([], dtype=torch.long)\n",
        "  for cls in range(num_cls): # 각 클래스마다 정의된 데이터 개수 만큼 무작위로 뽑아 저장\n",
        "    idx = np.where(labels.numpy() == cls)[0] # 이때 np.where를 사용하기 위해 labels 텐서를 넘파이 배열로 바꿔 사용\n",
        "    shuffled_idx = np.random.choice(len(idx), len(idx), replace=True)\n",
        "    data1 = torch.cat([data1, data[shuffled_idx[:num_data_per_class]]], dim=0)\n",
        "    data2 = torch.cat([data2, data[shuffled_idx[num_data_per_class:]]], dim=0)\n",
        "    labels1 = torch.cat([labels1, labels[shuffled_idx[:num_data_per_class]]], dim=0)\n",
        "    labels2 = torch.cat([labels2, labels[shuffled_idx[:num_data_per_class]]], dim=0)\n",
        "  return data1, data2, labels1, labels2"
      ],
      "metadata": {
        "id": "ssxqB-L33rcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "trainset = torchvision.datasets.MNIST(root='/content/drive/MyDrive/deeplearning/data', train=True, download=True) # 숫자 판별 MNIST 데이터를 불러옴.\n",
        "labeled_data, unlabeled_data, labels, unlabels = balanced_subset(trainset.data, # 이번 실험에서는 라벨링된 데이터가 2000개만 있다고 가정, 학습 데이터, 검증 데이터를 각각 1000개씩 사용, 나머지는 라벨링이 안된 데이터라고 가정.\n",
        "                                                                 trainset.targets, num_cls=10, num_data=2000)\n",
        "train_images, val_images, train_labels, val_labels = balanced_subset(labeled_data, labels,\n",
        "                                                                     num_cls=10, num_data=1000)"
      ],
      "metadata": {
        "id": "mFAyg6YG4S-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더 정의\n",
        "train_images = train_images.unsqueeze(1) # CNN은 4차원 입력 이미지 필요. But, 1채널인 MNIST 데이터는 (배치사이즈, 이미지 너비, 이미지 높이) 형태인 3차원\n",
        "# => unsqueeze(1)을 통해 3차원 텐서를 4차원 텐서 (배치사이즈, 1, 이미지 너비, 이미지 높이)로 변환.\n",
        "val_images = val_images.unsqueeze(1)\n",
        "trainset = MyDataset(train_images, train_labels, transform=TrainTransform()) # 학습 데이터에는 TrainTransform()을 적용\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle = True)\n",
        "validationset = MyDataset(val_images, val_labels) # 나머지 세트에 대해서는 적용 X.\n",
        "valloader = torch.utils.data.DataLoader(validationset, batch_size=128, shuffle=False)\n",
        "unlabeled_images = unlabeled_data.unsqueeze(1)\n",
        "unlabeledset = MyDataset(unlabeled_images, unlabels)\n",
        "unlabeledloader = torch.utils.data.DataLoader(unlabeledset, batch_size=256, shuffle=True)\n",
        "transform = transforms.Compose([transforms.ToTensor()]) # 평가 데이터를 불러옴\n",
        "testset = torchvision.datasets.MNIST(root='/content/drive/MyDrive/deeplearning/data', train=False, download=True,\n",
        "                                     transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)"
      ],
      "metadata": {
        "id": "ah4y8jrE5-fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "class Net(nn.Module): # 임의의 모델 정의\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(1, 64, 3), nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.Conv2d(64, 192, 3, padding=1), nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2))\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(192*6*6, 1024), nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(1024, 512), nn.ReLU(),\n",
        "        nn.Linear(512,10))\n",
        "  def forward(self,x):\n",
        "    x = self.features(x)\n",
        "    x = x.view(-1, 192*6*6)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "model = Net().to(device)"
      ],
      "metadata": {
        "id": "PW9K1yWQ7ieI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수 및 최적화 기법 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "iKrjG1_e8YFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도 평가 함수 정의\n",
        "def accuracy(dataloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for data in dataloader:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total+=labels.size(0)\n",
        "      correct+=(predicted==labels).sum().item()\n",
        "  acc = 100*correct/total\n",
        "  model.train()\n",
        "  return acc"
      ],
      "metadata": {
        "id": "ucrSraA28jkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 지도 학습 수행\n",
        "# 기준 성능을 알아보기 위해 1000개의 라벨링된 데이터로만 학습 진행\n",
        "best_acc = 0 # 검증 정확도를 기준으로 모델을 저장하기 위해 변수 선언\n",
        "for epoch in range(501): # 학습 데이터를 이용해 학습하고, 학습 정확도 계산\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for traindata in trainloader:\n",
        "    inputs, labels = traindata[0].to(device), traindata[1].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    _, predicted = torch.max(outputs.detach(), 1)\n",
        "    total+=labels.size(0)\n",
        "    correct+=(predicted==labels).sum().item()\n",
        "  val_acc = accuracy(valloader) # 검증 정확도를 계산, 가장 높은 검증 정확도를 기준으로 모델 파라미터를 정함.\n",
        "  if val_acc>=best_acc:\n",
        "    best_acc=val_acc\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/deeplearning/models/cifar_model_for_pseudo_baseline.pth')\n",
        "    print('[%d] train acc: %.2f, validation acc:%.2f - Saved the best model' %(epoch, 100*correct/total, val_acc))\n",
        "  elif epoch%10==0: # 학습 상황을 알 수 있도록 에포크 1-마다 학습 정확도와 검증 정확도 출력\n",
        "    print('[%d] train acc: %.2f, validation acc: %.2f' %(epoch, 100*correct/total, val_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0ois3wm9Cue",
        "outputId": "f4e754b3-7b14-4668-b5da-cdbf69017991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] train acc: 16.80, validation acc:11.10 - Saved the best model\n",
            "[10] train acc: 94.70, validation acc: 10.40\n",
            "[20] train acc: 99.30, validation acc: 10.40\n",
            "[26] train acc: 99.70, validation acc:11.70 - Saved the best model\n",
            "[30] train acc: 99.90, validation acc: 10.70\n",
            "[40] train acc: 99.90, validation acc: 10.90\n",
            "[50] train acc: 99.70, validation acc: 10.80\n",
            "[60] train acc: 100.00, validation acc: 11.60\n",
            "[70] train acc: 99.60, validation acc: 10.20\n",
            "[80] train acc: 99.90, validation acc:11.70 - Saved the best model\n",
            "[81] train acc: 99.60, validation acc:11.80 - Saved the best model\n",
            "[90] train acc: 99.80, validation acc: 11.10\n",
            "[100] train acc: 99.70, validation acc: 11.10\n",
            "[110] train acc: 99.60, validation acc: 10.60\n",
            "[120] train acc: 99.90, validation acc: 10.90\n",
            "[130] train acc: 99.90, validation acc: 11.10\n",
            "[140] train acc: 99.50, validation acc: 10.70\n",
            "[150] train acc: 99.80, validation acc: 10.50\n",
            "[154] train acc: 99.60, validation acc:11.80 - Saved the best model\n",
            "[160] train acc: 99.50, validation acc: 11.60\n",
            "[167] train acc: 99.50, validation acc:12.20 - Saved the best model\n",
            "[170] train acc: 99.20, validation acc: 11.60\n",
            "[180] train acc: 100.00, validation acc: 11.40\n",
            "[185] train acc: 99.70, validation acc:12.30 - Saved the best model\n",
            "[190] train acc: 99.80, validation acc: 11.30\n",
            "[200] train acc: 99.20, validation acc: 11.20\n",
            "[210] train acc: 99.90, validation acc: 10.90\n",
            "[220] train acc: 99.90, validation acc: 11.80\n",
            "[230] train acc: 99.90, validation acc: 11.20\n",
            "[240] train acc: 99.70, validation acc: 11.20\n",
            "[250] train acc: 99.90, validation acc: 11.20\n",
            "[260] train acc: 100.00, validation acc: 11.00\n",
            "[270] train acc: 100.00, validation acc: 11.20\n",
            "[280] train acc: 99.90, validation acc: 11.10\n",
            "[290] train acc: 100.00, validation acc: 11.20\n",
            "[300] train acc: 99.80, validation acc: 10.80\n",
            "[310] train acc: 99.90, validation acc: 10.50\n",
            "[320] train acc: 99.90, validation acc: 10.80\n",
            "[330] train acc: 99.90, validation acc: 11.30\n",
            "[340] train acc: 100.00, validation acc: 11.00\n",
            "[347] train acc: 99.60, validation acc:12.30 - Saved the best model\n",
            "[350] train acc: 99.70, validation acc: 11.70\n",
            "[353] train acc: 100.00, validation acc:12.50 - Saved the best model\n",
            "[360] train acc: 99.80, validation acc: 11.30\n",
            "[370] train acc: 99.90, validation acc: 11.30\n",
            "[380] train acc: 99.40, validation acc: 10.70\n",
            "[390] train acc: 99.80, validation acc: 11.20\n",
            "[400] train acc: 100.00, validation acc: 10.70\n",
            "[410] train acc: 99.50, validation acc: 10.80\n",
            "[420] train acc: 100.00, validation acc: 10.60\n",
            "[430] train acc: 100.00, validation acc: 10.60\n",
            "[440] train acc: 99.90, validation acc: 10.60\n",
            "[450] train acc: 100.00, validation acc: 11.20\n",
            "[460] train acc: 99.90, validation acc: 10.40\n",
            "[470] train acc: 100.00, validation acc: 11.10\n",
            "[480] train acc: 100.00, validation acc: 11.30\n",
            "[490] train acc: 100.00, validation acc: 11.20\n",
            "[500] train acc: 100.00, validation acc: 10.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 지도 학습 성능 평가\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/deeplearning/models/cifar_model_for_pseudo_baseline.pth'))\n",
        "accuracy(testloader) # 저장된 베스트 모델을 가지고 와서, 평가 정확도를 측정함. 이때 지도 학습의 정확도는 67.79%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZwjRwZI9r2e",
        "outputId": "3ddf8565-cabf-4e8c-e251-dfa2397da05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67.79"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 준지도 학습1을 위한 모델 재정의\n",
        "model = Net().to(device) # 모델 파라미터 초기화, 준지도 학습 진행\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "pQFIkxiSFqmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 준지도 학습 1 수행\n",
        "# 의사 라벨링 : 정확한 라벨 & 부정확한 라벨 섞여있음 => 훈련 데이터와 동일하게 모델 최적화에 사용시 오히려 안좋아 => 훈련 라벨과 의사 라벨을 구분 & 따로 손실 함수(L_t와 L_p)를 계산한 뒤 둘을 더해 전체 손실 함수 L(L=L_t+alpha*L_p)을 정의.\n",
        "# 의사 라벨을 이용하는 손실 함수 부분에 가중치 alpha를 주어 학습 개입을 조절 가능. => alpha=0이면 학습 데이터로만 모델을 최적화 한다는 뜻, alpha가 커질수록 의사 라벨의 영향도가 커짐.\n",
        "# => 연구마다 영향도의 차이가 다를 수 있으니 적절한 alpha를 정의하는 것이 중요.\n",
        "alpha = 0\n",
        "alpha_t = 1e-4\n",
        "T1 = 100 # 이 예시에서는 처음 에포크 100번까지는 alpha=0으로 학습을 진행\n",
        "T2 = 450 # 이후 에포크가 450이 될때까지 일정하게 alpha를 높여 학습을 시행, 450회가 지나면 alpha를 alpha_t로 고정하여 학습을 진행하여 마무리 => alpha를 0부터 1e-4까지 점차 높여 학습 진행\n",
        "best_acc = 0\n",
        "for epoch in range(501):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for traindata, pseudodata in zip(trainloader, unlabeledloader): # zip을 이용, 두 개의 데이터로더 동시에 이용 가능\n",
        "    inputs, labels = traindata[0].to(device), traindata[1].to(device)\n",
        "    pinputs = pseudodata[0].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    if alpha > 0 : # 0보다 크면 의사 라벨로 함께 이용하여 손실 함수 계산\n",
        "      poutputs = model(pinputs)\n",
        "      _, plabels = torch.max(poutputs.detach(), 1)\n",
        "      loss = criterion(outputs, labels) + alpha*criterion(poutputs, plabels)\n",
        "    else: # alpha=0이면 학습 데이터만 이용하며 손실함수를 계산\n",
        "      loss = criterion(outputs, labels) # 첫 번째 의사 라벨 방법에서는 모델의 출력 벡터와 출력 벡터로 만든 예측 라벨과의 손실 함수를 계산하는 것!\n",
        "      # ex. (0.1, 0.6, 0.3)이라는 출력 벡터가 나왔다면 예측 라벨은 (0,1,0)이 되고 이 둘을 손실 함수에 넣어 계산하게 됨.\n",
        "    loss.backward()\n",
        "    optimizer.step() # 다음, 조건에 맞는 손실 함수를 기준으로 모델을 최적화\n",
        "    _, predicted = torch.max(outputs.detach(), 1) # 학습 정확도 계산을 위해 정답 개수, 총 라벨 개수 누적\n",
        "    total+=labels.size(0)\n",
        "    correct+=(predicted == labels).sum().item()\n",
        "    if (epoch>T1) and (epoch<T2): # 학습이 1회가 완료되면 epoch 확인하여 alpha 업데이트\n",
        "      alpha = alpha_t*(epoch - T1)/(T2-T1)\n",
        "    elif epoch>=T2:\n",
        "      alpha = alpha_t\n",
        "    val_acc = accuracy(valloader) # 검증 정확도를 계산, 가장 높은 검증 정확도를 기준으로 모델 파라미터 저장\n",
        "    if val_acc>=best_acc:\n",
        "      best_acc = val_acc\n",
        "      torch.save(model.state_dict(), '/content/drive/MyDrive/deeplearning/models/cifar_model_for_pseudo_label.pth')\n",
        "      print('[%d]train acc:%.2f, validation acc:%.2f -Saved the best model'%(epoch, 100*correct/total, val_acc))\n",
        "    elif epoch%10==0: # 학습 상황을 알 수 있도록 epoch 10마다 학습 정확도와 검증 정확도 출력\n",
        "      print('[%d]train acc:%.2f, validation acc:%.2f'%(epoch, 100*correct/total, val_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF2xfo9nF7Dd",
        "outputId": "b4672c6b-e934-4b3c-bfff-05541686ff0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]train acc:100.00, validation acc:11.70 -Saved the best model\n",
            "[0]train acc:100.00, validation acc:11.80 -Saved the best model\n",
            "[0]train acc:100.00, validation acc:11.80 -Saved the best model\n",
            "[0]train acc:100.00, validation acc:11.80 -Saved the best model\n",
            "[0]train acc:100.00, validation acc:11.80 -Saved the best model\n",
            "[0]train acc:100.00, validation acc:11.80 -Saved the best model\n",
            "[0]train acc:100.00, validation acc:11.80 -Saved the best model\n",
            "[0]train acc:100.00, validation acc:11.80 -Saved the best model\n",
            "[1]train acc:100.00, validation acc:11.80 -Saved the best model\n",
            "[1]train acc:100.00, validation acc:11.80 -Saved the best model\n",
            "[1]train acc:100.00, validation acc:11.90 -Saved the best model\n",
            "[1]train acc:100.00, validation acc:11.90 -Saved the best model\n",
            "[2]train acc:99.87, validation acc:11.90 -Saved the best model\n",
            "[2]train acc:99.89, validation acc:12.00 -Saved the best model\n",
            "[10]train acc:100.00, validation acc:11.30\n",
            "[10]train acc:100.00, validation acc:11.30\n",
            "[10]train acc:100.00, validation acc:11.30\n",
            "[10]train acc:100.00, validation acc:11.30\n",
            "[10]train acc:100.00, validation acc:11.30\n",
            "[10]train acc:100.00, validation acc:11.10\n",
            "[10]train acc:99.89, validation acc:11.40\n",
            "[10]train acc:99.90, validation acc:11.50\n",
            "[11]train acc:100.00, validation acc:12.30 -Saved the best model\n",
            "[11]train acc:100.00, validation acc:12.40 -Saved the best model\n",
            "[12]train acc:100.00, validation acc:12.50 -Saved the best model\n",
            "[12]train acc:99.74, validation acc:12.50 -Saved the best model\n",
            "[12]train acc:99.78, validation acc:12.50 -Saved the best model\n",
            "[16]train acc:99.84, validation acc:12.60 -Saved the best model\n",
            "[16]train acc:99.87, validation acc:12.60 -Saved the best model\n",
            "[16]train acc:99.89, validation acc:12.90 -Saved the best model\n",
            "[16]train acc:99.90, validation acc:12.90 -Saved the best model\n",
            "[17]train acc:100.00, validation acc:12.90 -Saved the best model\n",
            "[17]train acc:100.00, validation acc:12.90 -Saved the best model\n",
            "[17]train acc:100.00, validation acc:12.90 -Saved the best model\n",
            "[17]train acc:100.00, validation acc:12.90 -Saved the best model\n",
            "[20]train acc:100.00, validation acc:12.20\n",
            "[20]train acc:100.00, validation acc:12.10\n",
            "[20]train acc:100.00, validation acc:12.20\n",
            "[20]train acc:100.00, validation acc:12.20\n",
            "[20]train acc:100.00, validation acc:12.00\n",
            "[20]train acc:99.87, validation acc:11.90\n",
            "[20]train acc:99.89, validation acc:11.90\n",
            "[20]train acc:99.80, validation acc:12.30\n",
            "[30]train acc:100.00, validation acc:12.20\n",
            "[30]train acc:100.00, validation acc:12.00\n",
            "[30]train acc:100.00, validation acc:11.90\n",
            "[30]train acc:100.00, validation acc:11.50\n",
            "[30]train acc:99.84, validation acc:11.40\n",
            "[30]train acc:99.87, validation acc:11.00\n",
            "[30]train acc:99.89, validation acc:10.90\n",
            "[30]train acc:99.90, validation acc:10.90\n",
            "[40]train acc:100.00, validation acc:11.90\n",
            "[40]train acc:100.00, validation acc:11.90\n",
            "[40]train acc:100.00, validation acc:11.90\n",
            "[40]train acc:100.00, validation acc:11.80\n",
            "[40]train acc:100.00, validation acc:11.70\n",
            "[40]train acc:100.00, validation acc:11.70\n",
            "[40]train acc:100.00, validation acc:11.60\n",
            "[40]train acc:100.00, validation acc:11.60\n",
            "[50]train acc:100.00, validation acc:11.80\n",
            "[50]train acc:100.00, validation acc:11.80\n",
            "[50]train acc:100.00, validation acc:11.80\n",
            "[50]train acc:100.00, validation acc:11.80\n",
            "[50]train acc:100.00, validation acc:11.80\n",
            "[50]train acc:100.00, validation acc:11.80\n",
            "[50]train acc:100.00, validation acc:11.80\n",
            "[50]train acc:100.00, validation acc:11.80\n",
            "[60]train acc:100.00, validation acc:11.80\n",
            "[60]train acc:99.61, validation acc:11.80\n",
            "[60]train acc:99.74, validation acc:11.90\n",
            "[60]train acc:99.80, validation acc:11.90\n",
            "[60]train acc:99.84, validation acc:11.50\n",
            "[60]train acc:99.87, validation acc:11.80\n",
            "[60]train acc:99.89, validation acc:12.00\n",
            "[60]train acc:99.90, validation acc:12.00\n",
            "[70]train acc:100.00, validation acc:11.10\n",
            "[70]train acc:100.00, validation acc:11.10\n",
            "[70]train acc:100.00, validation acc:11.10\n",
            "[70]train acc:100.00, validation acc:11.10\n",
            "[70]train acc:100.00, validation acc:11.00\n",
            "[70]train acc:100.00, validation acc:11.00\n",
            "[70]train acc:100.00, validation acc:11.10\n",
            "[70]train acc:100.00, validation acc:11.10\n",
            "[80]train acc:100.00, validation acc:10.90\n",
            "[80]train acc:100.00, validation acc:10.90\n",
            "[80]train acc:100.00, validation acc:10.90\n",
            "[80]train acc:100.00, validation acc:10.90\n",
            "[80]train acc:100.00, validation acc:10.90\n",
            "[80]train acc:100.00, validation acc:10.90\n",
            "[80]train acc:100.00, validation acc:10.90\n",
            "[80]train acc:100.00, validation acc:10.90\n",
            "[90]train acc:100.00, validation acc:11.50\n",
            "[90]train acc:100.00, validation acc:11.50\n",
            "[90]train acc:100.00, validation acc:11.50\n",
            "[90]train acc:100.00, validation acc:11.50\n",
            "[90]train acc:100.00, validation acc:11.50\n",
            "[90]train acc:99.87, validation acc:11.40\n",
            "[90]train acc:99.89, validation acc:11.10\n",
            "[90]train acc:99.90, validation acc:11.00\n",
            "[100]train acc:100.00, validation acc:11.10\n",
            "[100]train acc:100.00, validation acc:11.10\n",
            "[100]train acc:100.00, validation acc:11.10\n",
            "[100]train acc:100.00, validation acc:11.10\n",
            "[100]train acc:100.00, validation acc:11.10\n",
            "[100]train acc:100.00, validation acc:11.10\n",
            "[100]train acc:100.00, validation acc:11.10\n",
            "[100]train acc:100.00, validation acc:11.10\n",
            "[110]train acc:100.00, validation acc:11.70\n",
            "[110]train acc:100.00, validation acc:11.70\n",
            "[110]train acc:100.00, validation acc:11.80\n",
            "[110]train acc:100.00, validation acc:11.70\n",
            "[110]train acc:100.00, validation acc:11.70\n",
            "[110]train acc:100.00, validation acc:11.70\n",
            "[110]train acc:100.00, validation acc:11.70\n",
            "[110]train acc:100.00, validation acc:11.80\n",
            "[120]train acc:100.00, validation acc:12.20\n",
            "[120]train acc:100.00, validation acc:12.20\n",
            "[120]train acc:100.00, validation acc:12.50\n",
            "[120]train acc:99.80, validation acc:12.20\n",
            "[120]train acc:99.84, validation acc:12.10\n",
            "[120]train acc:99.87, validation acc:11.90\n",
            "[120]train acc:99.78, validation acc:12.00\n",
            "[120]train acc:99.80, validation acc:12.20\n",
            "[130]train acc:100.00, validation acc:11.80\n",
            "[130]train acc:99.61, validation acc:11.90\n",
            "[130]train acc:99.74, validation acc:11.80\n",
            "[130]train acc:99.80, validation acc:11.90\n",
            "[130]train acc:99.84, validation acc:11.70\n",
            "[130]train acc:99.87, validation acc:11.50\n",
            "[130]train acc:99.67, validation acc:11.50\n",
            "[130]train acc:99.70, validation acc:11.10\n",
            "[140]train acc:100.00, validation acc:11.70\n",
            "[140]train acc:100.00, validation acc:11.70\n",
            "[140]train acc:100.00, validation acc:11.70\n",
            "[140]train acc:100.00, validation acc:11.70\n",
            "[140]train acc:100.00, validation acc:11.70\n",
            "[140]train acc:100.00, validation acc:11.70\n",
            "[140]train acc:100.00, validation acc:11.70\n",
            "[140]train acc:100.00, validation acc:11.70\n",
            "[150]train acc:100.00, validation acc:11.80\n",
            "[150]train acc:100.00, validation acc:11.80\n",
            "[150]train acc:100.00, validation acc:11.70\n",
            "[150]train acc:100.00, validation acc:11.70\n",
            "[150]train acc:100.00, validation acc:11.70\n",
            "[150]train acc:100.00, validation acc:12.00\n",
            "[150]train acc:100.00, validation acc:12.00\n",
            "[150]train acc:100.00, validation acc:11.90\n",
            "[160]train acc:100.00, validation acc:11.70\n",
            "[160]train acc:100.00, validation acc:11.70\n",
            "[160]train acc:100.00, validation acc:11.70\n",
            "[160]train acc:99.80, validation acc:11.70\n",
            "[160]train acc:99.84, validation acc:11.80\n",
            "[160]train acc:99.74, validation acc:11.70\n",
            "[160]train acc:99.78, validation acc:11.80\n",
            "[160]train acc:99.80, validation acc:11.20\n",
            "[170]train acc:100.00, validation acc:11.40\n",
            "[170]train acc:100.00, validation acc:11.40\n",
            "[170]train acc:100.00, validation acc:11.40\n",
            "[170]train acc:100.00, validation acc:11.20\n",
            "[170]train acc:100.00, validation acc:11.30\n",
            "[170]train acc:100.00, validation acc:11.30\n",
            "[170]train acc:100.00, validation acc:11.40\n",
            "[170]train acc:100.00, validation acc:11.40\n",
            "[180]train acc:100.00, validation acc:11.10\n",
            "[180]train acc:100.00, validation acc:11.00\n",
            "[180]train acc:100.00, validation acc:11.00\n",
            "[180]train acc:100.00, validation acc:11.00\n",
            "[180]train acc:100.00, validation acc:11.00\n",
            "[180]train acc:100.00, validation acc:11.00\n",
            "[180]train acc:100.00, validation acc:11.00\n",
            "[180]train acc:100.00, validation acc:11.00\n",
            "[190]train acc:100.00, validation acc:11.10\n",
            "[190]train acc:100.00, validation acc:11.10\n",
            "[190]train acc:100.00, validation acc:11.00\n",
            "[190]train acc:100.00, validation acc:11.00\n",
            "[190]train acc:100.00, validation acc:11.00\n",
            "[190]train acc:100.00, validation acc:10.90\n",
            "[190]train acc:100.00, validation acc:10.90\n",
            "[190]train acc:99.90, validation acc:10.90\n",
            "[200]train acc:100.00, validation acc:11.60\n",
            "[200]train acc:100.00, validation acc:11.60\n",
            "[200]train acc:100.00, validation acc:11.60\n",
            "[200]train acc:100.00, validation acc:11.50\n",
            "[200]train acc:100.00, validation acc:11.30\n",
            "[200]train acc:100.00, validation acc:11.30\n",
            "[200]train acc:100.00, validation acc:11.30\n",
            "[200]train acc:100.00, validation acc:11.30\n",
            "[210]train acc:100.00, validation acc:11.20\n",
            "[210]train acc:100.00, validation acc:11.20\n",
            "[210]train acc:100.00, validation acc:11.20\n",
            "[210]train acc:100.00, validation acc:11.20\n",
            "[210]train acc:100.00, validation acc:11.20\n",
            "[210]train acc:100.00, validation acc:11.20\n",
            "[210]train acc:100.00, validation acc:11.20\n",
            "[210]train acc:100.00, validation acc:11.20\n",
            "[220]train acc:100.00, validation acc:11.40\n",
            "[220]train acc:100.00, validation acc:11.40\n",
            "[220]train acc:100.00, validation acc:11.20\n",
            "[220]train acc:100.00, validation acc:11.20\n",
            "[220]train acc:100.00, validation acc:11.20\n",
            "[220]train acc:100.00, validation acc:11.20\n",
            "[220]train acc:100.00, validation acc:11.20\n",
            "[220]train acc:100.00, validation acc:10.80\n",
            "[230]train acc:100.00, validation acc:11.20\n",
            "[230]train acc:100.00, validation acc:11.20\n",
            "[230]train acc:100.00, validation acc:11.20\n",
            "[230]train acc:100.00, validation acc:11.20\n",
            "[230]train acc:100.00, validation acc:11.20\n",
            "[230]train acc:100.00, validation acc:11.20\n",
            "[230]train acc:100.00, validation acc:11.20\n",
            "[230]train acc:100.00, validation acc:11.20\n",
            "[240]train acc:100.00, validation acc:11.60\n",
            "[240]train acc:100.00, validation acc:11.60\n",
            "[240]train acc:100.00, validation acc:11.50\n",
            "[240]train acc:100.00, validation acc:11.50\n",
            "[240]train acc:100.00, validation acc:11.50\n",
            "[240]train acc:100.00, validation acc:11.50\n",
            "[240]train acc:100.00, validation acc:11.50\n",
            "[240]train acc:100.00, validation acc:11.50\n",
            "[250]train acc:100.00, validation acc:10.20\n",
            "[250]train acc:100.00, validation acc:10.20\n",
            "[250]train acc:100.00, validation acc:10.10\n",
            "[250]train acc:100.00, validation acc:10.10\n",
            "[250]train acc:100.00, validation acc:10.10\n",
            "[250]train acc:100.00, validation acc:10.20\n",
            "[250]train acc:100.00, validation acc:10.20\n",
            "[250]train acc:100.00, validation acc:10.20\n",
            "[260]train acc:100.00, validation acc:10.80\n",
            "[260]train acc:100.00, validation acc:10.70\n",
            "[260]train acc:100.00, validation acc:10.80\n",
            "[260]train acc:100.00, validation acc:10.60\n",
            "[260]train acc:100.00, validation acc:10.80\n",
            "[260]train acc:100.00, validation acc:10.80\n",
            "[260]train acc:100.00, validation acc:10.80\n",
            "[260]train acc:100.00, validation acc:10.70\n",
            "[270]train acc:100.00, validation acc:11.50\n",
            "[270]train acc:99.61, validation acc:11.30\n",
            "[270]train acc:99.48, validation acc:11.50\n",
            "[270]train acc:99.41, validation acc:11.60\n",
            "[270]train acc:99.38, validation acc:11.40\n",
            "[270]train acc:99.48, validation acc:11.50\n",
            "[270]train acc:99.55, validation acc:11.70\n",
            "[270]train acc:99.50, validation acc:11.60\n",
            "[280]train acc:100.00, validation acc:11.90\n",
            "[280]train acc:99.61, validation acc:11.80\n",
            "[280]train acc:99.74, validation acc:11.60\n",
            "[280]train acc:99.80, validation acc:11.70\n",
            "[280]train acc:99.69, validation acc:11.70\n",
            "[280]train acc:99.61, validation acc:11.70\n",
            "[280]train acc:99.55, validation acc:11.70\n",
            "[280]train acc:99.50, validation acc:11.50\n",
            "[290]train acc:100.00, validation acc:11.70\n",
            "[290]train acc:100.00, validation acc:11.70\n",
            "[290]train acc:100.00, validation acc:11.70\n",
            "[290]train acc:100.00, validation acc:11.70\n",
            "[290]train acc:100.00, validation acc:11.70\n",
            "[290]train acc:100.00, validation acc:11.70\n",
            "[290]train acc:100.00, validation acc:11.70\n",
            "[290]train acc:100.00, validation acc:11.70\n",
            "[300]train acc:100.00, validation acc:11.90\n",
            "[300]train acc:100.00, validation acc:11.90\n",
            "[300]train acc:100.00, validation acc:11.90\n",
            "[300]train acc:99.80, validation acc:11.60\n",
            "[300]train acc:99.84, validation acc:11.40\n",
            "[300]train acc:99.87, validation acc:11.00\n",
            "[300]train acc:99.89, validation acc:11.10\n",
            "[300]train acc:99.90, validation acc:11.20\n",
            "[310]train acc:100.00, validation acc:12.10\n",
            "[310]train acc:100.00, validation acc:12.00\n",
            "[310]train acc:99.74, validation acc:12.20\n",
            "[310]train acc:99.80, validation acc:12.10\n",
            "[310]train acc:99.84, validation acc:12.20\n",
            "[310]train acc:99.87, validation acc:12.30\n",
            "[310]train acc:99.78, validation acc:12.30\n",
            "[310]train acc:99.80, validation acc:12.30\n",
            "[320]train acc:100.00, validation acc:11.20\n",
            "[320]train acc:100.00, validation acc:11.20\n",
            "[320]train acc:100.00, validation acc:11.30\n",
            "[320]train acc:100.00, validation acc:11.30\n",
            "[320]train acc:100.00, validation acc:11.30\n",
            "[320]train acc:99.87, validation acc:11.40\n",
            "[320]train acc:99.89, validation acc:11.20\n",
            "[320]train acc:99.90, validation acc:11.20\n",
            "[330]train acc:100.00, validation acc:11.00\n",
            "[330]train acc:100.00, validation acc:11.00\n",
            "[330]train acc:100.00, validation acc:11.00\n",
            "[330]train acc:100.00, validation acc:11.00\n",
            "[330]train acc:99.84, validation acc:11.10\n",
            "[330]train acc:99.87, validation acc:11.20\n",
            "[330]train acc:99.89, validation acc:11.30\n",
            "[330]train acc:99.90, validation acc:11.30\n",
            "[340]train acc:100.00, validation acc:11.30\n",
            "[340]train acc:100.00, validation acc:11.10\n",
            "[340]train acc:100.00, validation acc:11.10\n",
            "[340]train acc:100.00, validation acc:11.00\n",
            "[340]train acc:100.00, validation acc:11.10\n",
            "[340]train acc:100.00, validation acc:11.10\n",
            "[340]train acc:100.00, validation acc:10.70\n",
            "[340]train acc:100.00, validation acc:10.80\n",
            "[350]train acc:100.00, validation acc:11.30\n",
            "[350]train acc:100.00, validation acc:11.10\n",
            "[350]train acc:100.00, validation acc:11.20\n",
            "[350]train acc:100.00, validation acc:11.20\n",
            "[350]train acc:100.00, validation acc:10.90\n",
            "[350]train acc:100.00, validation acc:11.00\n",
            "[350]train acc:100.00, validation acc:10.90\n",
            "[350]train acc:100.00, validation acc:11.10\n",
            "[360]train acc:100.00, validation acc:11.20\n",
            "[360]train acc:100.00, validation acc:11.20\n",
            "[360]train acc:100.00, validation acc:11.20\n",
            "[360]train acc:100.00, validation acc:11.20\n",
            "[360]train acc:100.00, validation acc:11.20\n",
            "[360]train acc:100.00, validation acc:11.20\n",
            "[360]train acc:100.00, validation acc:11.20\n",
            "[360]train acc:100.00, validation acc:11.20\n",
            "[370]train acc:100.00, validation acc:11.10\n",
            "[370]train acc:100.00, validation acc:11.10\n",
            "[370]train acc:100.00, validation acc:11.10\n",
            "[370]train acc:100.00, validation acc:11.10\n",
            "[370]train acc:100.00, validation acc:11.10\n",
            "[370]train acc:100.00, validation acc:11.10\n",
            "[370]train acc:100.00, validation acc:11.10\n",
            "[370]train acc:100.00, validation acc:11.10\n",
            "[380]train acc:100.00, validation acc:11.20\n",
            "[380]train acc:100.00, validation acc:11.20\n",
            "[380]train acc:100.00, validation acc:11.20\n",
            "[380]train acc:100.00, validation acc:11.20\n",
            "[380]train acc:100.00, validation acc:11.20\n",
            "[380]train acc:100.00, validation acc:11.20\n",
            "[380]train acc:100.00, validation acc:11.10\n",
            "[380]train acc:100.00, validation acc:11.10\n",
            "[390]train acc:100.00, validation acc:11.20\n",
            "[390]train acc:100.00, validation acc:11.20\n",
            "[390]train acc:100.00, validation acc:11.20\n",
            "[390]train acc:100.00, validation acc:11.20\n",
            "[390]train acc:100.00, validation acc:11.20\n",
            "[390]train acc:100.00, validation acc:11.20\n",
            "[390]train acc:100.00, validation acc:11.20\n",
            "[390]train acc:99.90, validation acc:11.50\n",
            "[400]train acc:100.00, validation acc:11.10\n",
            "[400]train acc:100.00, validation acc:11.10\n",
            "[400]train acc:100.00, validation acc:11.10\n",
            "[400]train acc:100.00, validation acc:11.10\n",
            "[400]train acc:100.00, validation acc:11.10\n",
            "[400]train acc:100.00, validation acc:11.20\n",
            "[400]train acc:100.00, validation acc:11.20\n",
            "[400]train acc:100.00, validation acc:11.20\n",
            "[410]train acc:100.00, validation acc:11.30\n",
            "[410]train acc:100.00, validation acc:11.30\n",
            "[410]train acc:100.00, validation acc:11.40\n",
            "[410]train acc:100.00, validation acc:11.50\n",
            "[410]train acc:100.00, validation acc:11.50\n",
            "[410]train acc:100.00, validation acc:11.60\n",
            "[410]train acc:99.89, validation acc:11.50\n",
            "[410]train acc:99.90, validation acc:11.40\n",
            "[420]train acc:100.00, validation acc:11.00\n",
            "[420]train acc:100.00, validation acc:11.00\n",
            "[420]train acc:100.00, validation acc:10.90\n",
            "[420]train acc:100.00, validation acc:10.90\n",
            "[420]train acc:100.00, validation acc:10.90\n",
            "[420]train acc:100.00, validation acc:10.90\n",
            "[420]train acc:100.00, validation acc:10.90\n",
            "[420]train acc:100.00, validation acc:11.00\n",
            "[430]train acc:100.00, validation acc:11.10\n",
            "[430]train acc:100.00, validation acc:11.10\n",
            "[430]train acc:100.00, validation acc:11.30\n",
            "[430]train acc:100.00, validation acc:11.30\n",
            "[430]train acc:100.00, validation acc:11.30\n",
            "[430]train acc:100.00, validation acc:11.30\n",
            "[430]train acc:100.00, validation acc:11.30\n",
            "[430]train acc:100.00, validation acc:11.30\n",
            "[440]train acc:100.00, validation acc:11.30\n",
            "[440]train acc:100.00, validation acc:11.30\n",
            "[440]train acc:100.00, validation acc:11.20\n",
            "[440]train acc:100.00, validation acc:11.20\n",
            "[440]train acc:100.00, validation acc:11.50\n",
            "[440]train acc:100.00, validation acc:11.50\n",
            "[440]train acc:100.00, validation acc:11.50\n",
            "[440]train acc:100.00, validation acc:11.50\n",
            "[450]train acc:100.00, validation acc:10.00\n",
            "[450]train acc:100.00, validation acc:10.00\n",
            "[450]train acc:100.00, validation acc:10.10\n",
            "[450]train acc:100.00, validation acc:10.10\n",
            "[450]train acc:100.00, validation acc:10.10\n",
            "[450]train acc:100.00, validation acc:10.10\n",
            "[450]train acc:100.00, validation acc:10.10\n",
            "[450]train acc:100.00, validation acc:10.10\n",
            "[460]train acc:100.00, validation acc:11.10\n",
            "[460]train acc:100.00, validation acc:11.20\n",
            "[460]train acc:100.00, validation acc:11.40\n",
            "[460]train acc:100.00, validation acc:11.50\n",
            "[460]train acc:100.00, validation acc:11.80\n",
            "[460]train acc:100.00, validation acc:11.80\n",
            "[460]train acc:100.00, validation acc:11.70\n",
            "[460]train acc:100.00, validation acc:11.60\n",
            "[470]train acc:100.00, validation acc:11.10\n",
            "[470]train acc:100.00, validation acc:11.10\n",
            "[470]train acc:100.00, validation acc:11.00\n",
            "[470]train acc:100.00, validation acc:11.00\n",
            "[470]train acc:100.00, validation acc:11.00\n",
            "[470]train acc:100.00, validation acc:11.00\n",
            "[470]train acc:100.00, validation acc:11.00\n",
            "[470]train acc:100.00, validation acc:11.00\n",
            "[480]train acc:100.00, validation acc:11.20\n",
            "[480]train acc:100.00, validation acc:11.20\n",
            "[480]train acc:100.00, validation acc:11.30\n",
            "[480]train acc:100.00, validation acc:11.30\n",
            "[480]train acc:100.00, validation acc:10.90\n",
            "[480]train acc:100.00, validation acc:10.90\n",
            "[480]train acc:100.00, validation acc:11.00\n",
            "[480]train acc:100.00, validation acc:11.00\n",
            "[490]train acc:100.00, validation acc:11.50\n",
            "[490]train acc:99.61, validation acc:11.40\n",
            "[490]train acc:99.74, validation acc:11.20\n",
            "[490]train acc:99.80, validation acc:11.20\n",
            "[490]train acc:99.84, validation acc:11.30\n",
            "[490]train acc:99.87, validation acc:11.40\n",
            "[490]train acc:99.89, validation acc:10.90\n",
            "[490]train acc:99.90, validation acc:10.80\n",
            "[500]train acc:100.00, validation acc:11.30\n",
            "[500]train acc:100.00, validation acc:11.30\n",
            "[500]train acc:100.00, validation acc:11.30\n",
            "[500]train acc:100.00, validation acc:11.20\n",
            "[500]train acc:100.00, validation acc:11.10\n",
            "[500]train acc:100.00, validation acc:11.40\n",
            "[500]train acc:99.89, validation acc:11.40\n",
            "[500]train acc:99.80, validation acc:11.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 준지도 학습1 성능 평가\n",
        "# 평가 정확도가 기준 대비 2.54% 증가 한 %이다.(기준 73.8%)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/deeplearning/models/cifar_model_for_pseudo_label.pth'))\n",
        "accuracy(testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq-i85_pHkMX",
        "outputId": "b62aa742-f2a5-42a1-a7c3-e98e8f4dfb57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76.34"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 준지도 학습2를 위한 모델 재정의\n",
        "model = Net().to(device) # 손실함수와 최적화 방법 정의\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/deeplearning/models/cifar_model_for_pseudo_baseline.pth'))\n",
        "# 이번 방법에서는 학습 데이터로 학습된 사전 훈련 모델을 가지고 의사 라벨을 생성 & 이를 실제 라벨 처럼 사용\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "IEenklCZMkwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 의사 라벨 생성\n",
        "pseudo_threshold = 0.99\n",
        "pseudo_images = torch.tensor([], dtype=torch.float)\n",
        "pseudo_labels = torch.tensor([], dtype=torch.long)\n",
        "with torch.no_grad():\n",
        "  for data in tqdm(unlabeledloader):\n",
        "    model.eval()\n",
        "    images = data[0].to(device)\n",
        "    outputs = model(images)\n",
        "    outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "    max_val, predicted = torch.max(outputs.detach(), 1)\n",
        "    idx = np.where(max_val.cpu().numpy()>=pseudo_threshold)[0]\n",
        "    if len(idx)>0:\n",
        "      pseudo_images = torch.cat((pseudo_images, images.cpu()[idx]),0)\n",
        "      pseudo_labels = torch.cat((pseudo_labels, predicted.cpu()[idx]),0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWlUu8UUM2oC",
        "outputId": "84834317-4882-48fd-8203-790fe3fdafbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 69.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 준지도 학습2를 위한 데이터로더 정의\n",
        "pseudo_dataset = MyDataset(pseudo_images, pseudo_labels)\n",
        "pseudoloader = torch.utils.data.DataLoader(pseudo_dataset, batch_size=256, shuffle=True)"
      ],
      "metadata": {
        "id": "hAMcnDGAOQRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 준지도 학습2 수행\n",
        "alpha = 0\n",
        "alpha_t = 1e-4 # 의사 라벨링 개입에 대한 alpha 정의\n",
        "T1 = 20\n",
        "T2 = 450\n",
        "best_acc = 0"
      ],
      "metadata": {
        "id": "_K6k0Yn9Ofks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(501):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for traindata, pseudodata in zip(trainloader, pseudoloader): # zip을 이용, 두 개의 데이터로더 동시에 이용 가능\n",
        "    inputs, labels = traindata[0].to(device), traindata[1].to(device) # 학습 데이터를 불러옴.\n",
        "    pinputs, plabels = pseudodata[0].to(device), pseudodata[1].to(device) # 의사 라벨 데이터를 불러옴.\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs) # 모델을 통해 예측값을 산출, 손실 함수 계산\n",
        "    poutputs = model(pinputs)\n",
        "    loss = criterion(outputs, labels) + alpha*criterion(poutputs, plabels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    _, predicted = torch.max(outputs.detach(), 1) # 학습 정확도 계산을 위해 정답 개수와 총 라벨 개수 누적.\n",
        "    total+=labels.size(0)\n",
        "    correct+=(predicted==labels).sum().item()\n",
        "    if(epoch>T1) and (epoch<T2): # 학습이 1회 완료되면 epoch를 확인, alpha를 업데이트\n",
        "      alpha = alpha_t*(epoch - T1)/(T2-T1)\n",
        "    elif epoch>=T2:\n",
        "      alpha = alpha_t\n",
        "    val_acc=accuracy(valloader) # 검증 정확도를 계산, 가장 높은 검증 정확도를 기준으로 모델 파라미터 저장\n",
        "    if val_acc>=best_acc:\n",
        "      best_acc = val_acc\n",
        "      torch.save(model.state_dict(), '/content/drive/MyDrive/deeplearning/models/cifar_model_for_pseudo_label2.pth')\n",
        "      print('[%d] train acc:%.2f, validation acc:%.2f'%(epoch, 100*correct/total, val_acc))\n",
        "    elif epoch%10==0: # 학습 상황을 알 수 있도록 epoch 10마다 학습 정확도, 검증 정확도 출력.\n",
        "      print('[%d] train acc:%.2f, validation acc:%.2f'%(epoch, 100*correct/total, val_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaX6BH82OrxJ",
        "outputId": "3285d408-b549-4f7d-e093-b501496708cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] train acc:100.00, validation acc:10.40\n",
            "[0] train acc:100.00, validation acc:10.30\n",
            "[0] train acc:100.00, validation acc:10.80\n",
            "[0] train acc:100.00, validation acc:10.80\n",
            "[0] train acc:100.00, validation acc:11.40\n",
            "[0] train acc:100.00, validation acc:11.30\n",
            "[0] train acc:100.00, validation acc:10.90\n",
            "[0] train acc:100.00, validation acc:11.00\n",
            "[1] train acc:99.74, validation acc:11.70\n",
            "[1] train acc:99.84, validation acc:11.80\n",
            "[1] train acc:99.87, validation acc:11.90\n",
            "[2] train acc:99.80, validation acc:11.90\n",
            "[3] train acc:100.00, validation acc:12.00\n",
            "[3] train acc:100.00, validation acc:12.10\n",
            "[3] train acc:99.69, validation acc:12.10\n",
            "[3] train acc:99.74, validation acc:12.10\n",
            "[4] train acc:99.61, validation acc:12.20\n",
            "[4] train acc:99.61, validation acc:12.20\n",
            "[5] train acc:99.22, validation acc:12.30\n",
            "[5] train acc:99.48, validation acc:12.30\n",
            "[5] train acc:99.61, validation acc:12.30\n",
            "[5] train acc:99.69, validation acc:12.30\n",
            "[6] train acc:99.61, validation acc:12.50\n",
            "[6] train acc:99.87, validation acc:12.70\n",
            "[6] train acc:99.89, validation acc:12.70\n",
            "[10] train acc:99.22, validation acc:11.60\n",
            "[10] train acc:99.22, validation acc:11.20\n",
            "[10] train acc:99.48, validation acc:11.50\n",
            "[10] train acc:99.61, validation acc:11.60\n",
            "[10] train acc:99.53, validation acc:11.60\n",
            "[10] train acc:99.61, validation acc:11.60\n",
            "[10] train acc:99.67, validation acc:11.70\n",
            "[10] train acc:99.60, validation acc:12.10\n",
            "[11] train acc:99.84, validation acc:12.70\n",
            "[11] train acc:99.87, validation acc:12.70\n",
            "[12] train acc:99.69, validation acc:12.70\n",
            "[20] train acc:100.00, validation acc:10.40\n",
            "[20] train acc:100.00, validation acc:10.50\n",
            "[20] train acc:100.00, validation acc:10.60\n",
            "[20] train acc:100.00, validation acc:10.60\n",
            "[20] train acc:100.00, validation acc:10.80\n",
            "[20] train acc:100.00, validation acc:10.90\n",
            "[20] train acc:100.00, validation acc:10.90\n",
            "[20] train acc:100.00, validation acc:10.80\n",
            "[25] train acc:99.89, validation acc:12.70\n",
            "[25] train acc:99.90, validation acc:12.80\n",
            "[26] train acc:100.00, validation acc:12.80\n",
            "[26] train acc:100.00, validation acc:12.90\n",
            "[26] train acc:100.00, validation acc:12.90\n",
            "[26] train acc:100.00, validation acc:12.90\n",
            "[26] train acc:100.00, validation acc:12.90\n",
            "[26] train acc:100.00, validation acc:12.90\n",
            "[27] train acc:100.00, validation acc:12.90\n",
            "[27] train acc:100.00, validation acc:12.90\n",
            "[27] train acc:100.00, validation acc:13.00\n",
            "[27] train acc:100.00, validation acc:13.10\n",
            "[27] train acc:100.00, validation acc:13.30\n",
            "[30] train acc:100.00, validation acc:13.30\n",
            "[30] train acc:100.00, validation acc:13.30\n",
            "[30] train acc:100.00, validation acc:13.30\n",
            "[30] train acc:100.00, validation acc:13.30\n",
            "[30] train acc:100.00, validation acc:13.00\n",
            "[30] train acc:100.00, validation acc:12.80\n",
            "[30] train acc:100.00, validation acc:13.00\n",
            "[30] train acc:100.00, validation acc:13.00\n",
            "[40] train acc:100.00, validation acc:12.60\n",
            "[40] train acc:100.00, validation acc:12.10\n",
            "[40] train acc:100.00, validation acc:12.20\n",
            "[40] train acc:100.00, validation acc:12.40\n",
            "[40] train acc:100.00, validation acc:12.50\n",
            "[40] train acc:100.00, validation acc:13.10\n",
            "[40] train acc:100.00, validation acc:12.90\n",
            "[40] train acc:100.00, validation acc:12.90\n",
            "[50] train acc:100.00, validation acc:11.60\n",
            "[50] train acc:100.00, validation acc:11.00\n",
            "[50] train acc:100.00, validation acc:10.80\n",
            "[50] train acc:100.00, validation acc:10.80\n",
            "[50] train acc:100.00, validation acc:11.50\n",
            "[50] train acc:100.00, validation acc:11.50\n",
            "[50] train acc:100.00, validation acc:12.10\n",
            "[50] train acc:100.00, validation acc:12.60\n",
            "[60] train acc:100.00, validation acc:11.50\n",
            "[60] train acc:100.00, validation acc:10.50\n",
            "[60] train acc:100.00, validation acc:10.40\n",
            "[60] train acc:100.00, validation acc:10.60\n",
            "[60] train acc:100.00, validation acc:10.60\n",
            "[60] train acc:100.00, validation acc:10.40\n",
            "[60] train acc:100.00, validation acc:10.60\n",
            "[60] train acc:100.00, validation acc:10.90\n",
            "[70] train acc:100.00, validation acc:10.70\n",
            "[70] train acc:100.00, validation acc:10.80\n",
            "[70] train acc:100.00, validation acc:10.90\n",
            "[70] train acc:100.00, validation acc:11.10\n",
            "[70] train acc:100.00, validation acc:10.80\n",
            "[70] train acc:100.00, validation acc:11.60\n",
            "[70] train acc:100.00, validation acc:11.80\n",
            "[70] train acc:100.00, validation acc:11.60\n",
            "[80] train acc:100.00, validation acc:10.20\n",
            "[80] train acc:100.00, validation acc:10.10\n",
            "[80] train acc:100.00, validation acc:10.60\n",
            "[80] train acc:100.00, validation acc:10.50\n",
            "[80] train acc:100.00, validation acc:10.00\n",
            "[80] train acc:100.00, validation acc:10.40\n",
            "[80] train acc:100.00, validation acc:11.20\n",
            "[80] train acc:100.00, validation acc:11.70\n",
            "[90] train acc:100.00, validation acc:11.40\n",
            "[90] train acc:100.00, validation acc:12.10\n",
            "[90] train acc:100.00, validation acc:11.30\n",
            "[90] train acc:100.00, validation acc:11.70\n",
            "[90] train acc:100.00, validation acc:13.10\n",
            "[90] train acc:100.00, validation acc:12.90\n",
            "[90] train acc:100.00, validation acc:12.70\n",
            "[90] train acc:100.00, validation acc:11.60\n",
            "[100] train acc:100.00, validation acc:11.00\n",
            "[100] train acc:100.00, validation acc:12.00\n",
            "[100] train acc:100.00, validation acc:12.20\n",
            "[100] train acc:100.00, validation acc:12.70\n",
            "[100] train acc:100.00, validation acc:12.20\n",
            "[100] train acc:100.00, validation acc:12.00\n",
            "[100] train acc:100.00, validation acc:11.40\n",
            "[100] train acc:100.00, validation acc:12.10\n",
            "[110] train acc:100.00, validation acc:11.20\n",
            "[110] train acc:100.00, validation acc:11.40\n",
            "[110] train acc:100.00, validation acc:12.80\n",
            "[110] train acc:100.00, validation acc:12.50\n",
            "[110] train acc:100.00, validation acc:12.90\n",
            "[110] train acc:100.00, validation acc:11.70\n",
            "[110] train acc:100.00, validation acc:11.10\n",
            "[110] train acc:100.00, validation acc:11.40\n",
            "[120] train acc:100.00, validation acc:11.70\n",
            "[120] train acc:100.00, validation acc:11.90\n",
            "[120] train acc:100.00, validation acc:10.80\n",
            "[120] train acc:100.00, validation acc:9.90\n",
            "[120] train acc:100.00, validation acc:10.00\n",
            "[120] train acc:100.00, validation acc:9.90\n",
            "[120] train acc:100.00, validation acc:10.90\n",
            "[120] train acc:100.00, validation acc:11.80\n",
            "[130] train acc:100.00, validation acc:12.30\n",
            "[130] train acc:100.00, validation acc:12.90\n",
            "[130] train acc:100.00, validation acc:11.70\n",
            "[130] train acc:100.00, validation acc:10.80\n",
            "[130] train acc:100.00, validation acc:11.30\n",
            "[130] train acc:100.00, validation acc:11.90\n",
            "[130] train acc:100.00, validation acc:11.70\n",
            "[130] train acc:100.00, validation acc:11.80\n",
            "[140] train acc:100.00, validation acc:10.90\n",
            "[140] train acc:100.00, validation acc:12.00\n",
            "[140] train acc:100.00, validation acc:12.00\n",
            "[140] train acc:100.00, validation acc:12.10\n",
            "[140] train acc:100.00, validation acc:12.20\n",
            "[140] train acc:100.00, validation acc:11.40\n",
            "[140] train acc:100.00, validation acc:11.00\n",
            "[140] train acc:100.00, validation acc:11.00\n",
            "[150] train acc:100.00, validation acc:12.10\n",
            "[150] train acc:99.61, validation acc:11.40\n",
            "[150] train acc:99.74, validation acc:10.80\n",
            "[150] train acc:99.80, validation acc:11.00\n",
            "[150] train acc:99.84, validation acc:10.80\n",
            "[150] train acc:99.87, validation acc:11.00\n",
            "[150] train acc:99.89, validation acc:11.30\n",
            "[150] train acc:99.90, validation acc:10.90\n",
            "[160] train acc:100.00, validation acc:12.10\n",
            "[160] train acc:100.00, validation acc:12.20\n",
            "[160] train acc:100.00, validation acc:11.30\n",
            "[160] train acc:100.00, validation acc:9.70\n",
            "[160] train acc:100.00, validation acc:9.80\n",
            "[160] train acc:100.00, validation acc:10.20\n",
            "[160] train acc:100.00, validation acc:10.80\n",
            "[160] train acc:100.00, validation acc:12.60\n",
            "[170] train acc:100.00, validation acc:10.30\n",
            "[170] train acc:99.22, validation acc:10.80\n",
            "[170] train acc:99.48, validation acc:11.20\n",
            "[170] train acc:99.61, validation acc:11.20\n",
            "[170] train acc:99.69, validation acc:11.20\n",
            "[170] train acc:99.48, validation acc:10.80\n",
            "[170] train acc:99.55, validation acc:10.80\n",
            "[170] train acc:99.60, validation acc:11.10\n",
            "[180] train acc:99.22, validation acc:10.00\n",
            "[180] train acc:99.61, validation acc:10.00\n",
            "[180] train acc:99.74, validation acc:10.50\n",
            "[180] train acc:99.41, validation acc:9.70\n",
            "[180] train acc:99.53, validation acc:7.80\n",
            "[180] train acc:99.61, validation acc:8.80\n",
            "[180] train acc:99.67, validation acc:11.20\n",
            "[180] train acc:99.60, validation acc:11.10\n",
            "[190] train acc:100.00, validation acc:10.80\n",
            "[190] train acc:100.00, validation acc:10.20\n",
            "[190] train acc:100.00, validation acc:10.20\n",
            "[190] train acc:100.00, validation acc:10.30\n",
            "[190] train acc:100.00, validation acc:11.80\n",
            "[190] train acc:100.00, validation acc:10.50\n",
            "[190] train acc:99.89, validation acc:10.30\n",
            "[190] train acc:99.90, validation acc:10.60\n",
            "[200] train acc:100.00, validation acc:11.20\n",
            "[200] train acc:100.00, validation acc:10.40\n",
            "[200] train acc:100.00, validation acc:10.30\n",
            "[200] train acc:100.00, validation acc:10.20\n",
            "[200] train acc:100.00, validation acc:10.80\n",
            "[200] train acc:100.00, validation acc:10.90\n",
            "[200] train acc:100.00, validation acc:10.00\n",
            "[200] train acc:100.00, validation acc:10.40\n",
            "[210] train acc:100.00, validation acc:10.60\n",
            "[210] train acc:100.00, validation acc:10.60\n",
            "[210] train acc:100.00, validation acc:10.40\n",
            "[210] train acc:100.00, validation acc:10.00\n",
            "[210] train acc:99.84, validation acc:11.00\n",
            "[210] train acc:99.87, validation acc:10.80\n",
            "[210] train acc:99.89, validation acc:10.40\n",
            "[210] train acc:99.90, validation acc:10.40\n",
            "[220] train acc:100.00, validation acc:10.00\n",
            "[220] train acc:100.00, validation acc:10.20\n",
            "[220] train acc:100.00, validation acc:9.90\n",
            "[220] train acc:100.00, validation acc:10.20\n",
            "[220] train acc:100.00, validation acc:10.20\n",
            "[220] train acc:100.00, validation acc:10.40\n",
            "[220] train acc:100.00, validation acc:10.30\n",
            "[220] train acc:100.00, validation acc:10.30\n",
            "[230] train acc:100.00, validation acc:10.60\n",
            "[230] train acc:100.00, validation acc:10.80\n",
            "[230] train acc:100.00, validation acc:10.80\n",
            "[230] train acc:100.00, validation acc:11.10\n",
            "[230] train acc:100.00, validation acc:10.80\n",
            "[230] train acc:100.00, validation acc:11.10\n",
            "[230] train acc:99.89, validation acc:10.00\n",
            "[230] train acc:99.90, validation acc:10.10\n",
            "[240] train acc:100.00, validation acc:9.90\n",
            "[240] train acc:100.00, validation acc:10.10\n",
            "[240] train acc:99.74, validation acc:10.40\n",
            "[240] train acc:99.41, validation acc:10.50\n",
            "[240] train acc:99.38, validation acc:6.90\n",
            "[240] train acc:99.48, validation acc:10.70\n",
            "[240] train acc:99.55, validation acc:10.30\n",
            "[240] train acc:99.60, validation acc:10.10\n",
            "[250] train acc:100.00, validation acc:10.50\n",
            "[250] train acc:100.00, validation acc:10.50\n",
            "[250] train acc:100.00, validation acc:11.00\n",
            "[250] train acc:100.00, validation acc:11.10\n",
            "[250] train acc:100.00, validation acc:10.30\n",
            "[250] train acc:100.00, validation acc:10.30\n",
            "[250] train acc:100.00, validation acc:10.30\n",
            "[250] train acc:99.90, validation acc:10.00\n",
            "[260] train acc:100.00, validation acc:10.60\n",
            "[260] train acc:100.00, validation acc:11.10\n",
            "[260] train acc:100.00, validation acc:10.80\n",
            "[260] train acc:100.00, validation acc:10.40\n",
            "[260] train acc:100.00, validation acc:10.40\n",
            "[260] train acc:100.00, validation acc:10.70\n",
            "[260] train acc:100.00, validation acc:10.50\n",
            "[260] train acc:100.00, validation acc:10.80\n",
            "[270] train acc:100.00, validation acc:9.70\n",
            "[270] train acc:100.00, validation acc:10.70\n",
            "[270] train acc:100.00, validation acc:10.70\n",
            "[270] train acc:100.00, validation acc:10.70\n",
            "[270] train acc:100.00, validation acc:10.60\n",
            "[270] train acc:100.00, validation acc:9.80\n",
            "[270] train acc:100.00, validation acc:9.60\n",
            "[270] train acc:100.00, validation acc:9.60\n",
            "[280] train acc:100.00, validation acc:10.40\n",
            "[280] train acc:100.00, validation acc:10.60\n",
            "[280] train acc:100.00, validation acc:11.60\n",
            "[280] train acc:100.00, validation acc:10.50\n",
            "[280] train acc:100.00, validation acc:10.50\n",
            "[280] train acc:100.00, validation acc:10.70\n",
            "[280] train acc:100.00, validation acc:10.70\n",
            "[280] train acc:100.00, validation acc:10.80\n",
            "[290] train acc:100.00, validation acc:11.00\n",
            "[290] train acc:100.00, validation acc:10.60\n",
            "[290] train acc:100.00, validation acc:10.70\n",
            "[290] train acc:100.00, validation acc:10.40\n",
            "[290] train acc:100.00, validation acc:10.40\n",
            "[290] train acc:100.00, validation acc:10.30\n",
            "[290] train acc:100.00, validation acc:10.80\n",
            "[290] train acc:100.00, validation acc:10.80\n",
            "[300] train acc:100.00, validation acc:10.70\n",
            "[300] train acc:100.00, validation acc:11.00\n",
            "[300] train acc:100.00, validation acc:10.70\n",
            "[300] train acc:100.00, validation acc:11.30\n",
            "[300] train acc:99.84, validation acc:11.20\n",
            "[300] train acc:99.87, validation acc:10.00\n",
            "[300] train acc:99.89, validation acc:10.10\n",
            "[300] train acc:99.90, validation acc:9.90\n",
            "[310] train acc:100.00, validation acc:10.20\n",
            "[310] train acc:100.00, validation acc:10.20\n",
            "[310] train acc:100.00, validation acc:11.00\n",
            "[310] train acc:100.00, validation acc:10.50\n",
            "[310] train acc:100.00, validation acc:10.50\n",
            "[310] train acc:100.00, validation acc:11.10\n",
            "[310] train acc:100.00, validation acc:11.10\n",
            "[310] train acc:100.00, validation acc:10.30\n",
            "[320] train acc:100.00, validation acc:9.80\n",
            "[320] train acc:100.00, validation acc:9.80\n",
            "[320] train acc:100.00, validation acc:10.20\n",
            "[320] train acc:100.00, validation acc:11.00\n",
            "[320] train acc:100.00, validation acc:10.30\n",
            "[320] train acc:100.00, validation acc:10.60\n",
            "[320] train acc:100.00, validation acc:10.50\n",
            "[320] train acc:100.00, validation acc:10.60\n",
            "[330] train acc:100.00, validation acc:10.30\n",
            "[330] train acc:100.00, validation acc:10.40\n",
            "[330] train acc:100.00, validation acc:10.20\n",
            "[330] train acc:100.00, validation acc:10.10\n",
            "[330] train acc:100.00, validation acc:10.70\n",
            "[330] train acc:100.00, validation acc:11.20\n",
            "[330] train acc:100.00, validation acc:11.10\n",
            "[330] train acc:100.00, validation acc:10.60\n",
            "[340] train acc:100.00, validation acc:10.80\n",
            "[340] train acc:100.00, validation acc:10.60\n",
            "[340] train acc:100.00, validation acc:10.50\n",
            "[340] train acc:100.00, validation acc:10.10\n",
            "[340] train acc:100.00, validation acc:10.00\n",
            "[340] train acc:100.00, validation acc:10.00\n",
            "[340] train acc:100.00, validation acc:10.00\n",
            "[340] train acc:100.00, validation acc:10.10\n",
            "[350] train acc:99.22, validation acc:10.00\n",
            "[350] train acc:99.61, validation acc:10.40\n",
            "[350] train acc:99.74, validation acc:10.80\n",
            "[350] train acc:99.61, validation acc:10.30\n",
            "[350] train acc:99.69, validation acc:10.00\n",
            "[350] train acc:99.74, validation acc:10.00\n",
            "[350] train acc:99.67, validation acc:10.10\n",
            "[350] train acc:99.70, validation acc:10.10\n",
            "[360] train acc:100.00, validation acc:10.10\n",
            "[360] train acc:99.61, validation acc:10.20\n",
            "[360] train acc:99.74, validation acc:10.40\n",
            "[360] train acc:99.80, validation acc:10.70\n",
            "[360] train acc:99.84, validation acc:11.30\n",
            "[360] train acc:99.87, validation acc:10.60\n",
            "[360] train acc:99.89, validation acc:10.20\n",
            "[360] train acc:99.90, validation acc:10.50\n",
            "[370] train acc:100.00, validation acc:10.60\n",
            "[370] train acc:100.00, validation acc:10.90\n",
            "[370] train acc:100.00, validation acc:11.10\n",
            "[370] train acc:100.00, validation acc:10.80\n",
            "[370] train acc:100.00, validation acc:11.20\n",
            "[370] train acc:100.00, validation acc:11.10\n",
            "[370] train acc:100.00, validation acc:10.40\n",
            "[370] train acc:100.00, validation acc:10.30\n",
            "[380] train acc:100.00, validation acc:10.00\n",
            "[380] train acc:100.00, validation acc:9.60\n",
            "[380] train acc:100.00, validation acc:10.20\n",
            "[380] train acc:100.00, validation acc:9.60\n",
            "[380] train acc:100.00, validation acc:10.80\n",
            "[380] train acc:100.00, validation acc:10.20\n",
            "[380] train acc:100.00, validation acc:10.00\n",
            "[380] train acc:100.00, validation acc:10.10\n",
            "[390] train acc:100.00, validation acc:10.40\n",
            "[390] train acc:100.00, validation acc:10.40\n",
            "[390] train acc:100.00, validation acc:10.80\n",
            "[390] train acc:100.00, validation acc:10.70\n",
            "[390] train acc:100.00, validation acc:10.70\n",
            "[390] train acc:100.00, validation acc:11.00\n",
            "[390] train acc:100.00, validation acc:10.60\n",
            "[390] train acc:100.00, validation acc:10.70\n",
            "[400] train acc:100.00, validation acc:11.00\n",
            "[400] train acc:100.00, validation acc:11.50\n",
            "[400] train acc:100.00, validation acc:11.40\n",
            "[400] train acc:100.00, validation acc:10.80\n",
            "[400] train acc:100.00, validation acc:10.60\n",
            "[400] train acc:100.00, validation acc:11.00\n",
            "[400] train acc:100.00, validation acc:10.90\n",
            "[400] train acc:100.00, validation acc:10.90\n",
            "[410] train acc:100.00, validation acc:11.80\n",
            "[410] train acc:100.00, validation acc:11.30\n",
            "[410] train acc:100.00, validation acc:11.10\n",
            "[410] train acc:100.00, validation acc:10.10\n",
            "[410] train acc:100.00, validation acc:9.80\n",
            "[410] train acc:99.87, validation acc:10.30\n",
            "[410] train acc:99.89, validation acc:10.60\n",
            "[410] train acc:99.90, validation acc:10.80\n",
            "[420] train acc:100.00, validation acc:10.50\n",
            "[420] train acc:100.00, validation acc:10.50\n",
            "[420] train acc:100.00, validation acc:10.60\n",
            "[420] train acc:100.00, validation acc:10.50\n",
            "[420] train acc:100.00, validation acc:10.30\n",
            "[420] train acc:100.00, validation acc:9.80\n",
            "[420] train acc:100.00, validation acc:10.20\n",
            "[420] train acc:100.00, validation acc:10.20\n",
            "[430] train acc:100.00, validation acc:10.50\n",
            "[430] train acc:100.00, validation acc:10.50\n",
            "[430] train acc:100.00, validation acc:10.40\n",
            "[430] train acc:100.00, validation acc:10.80\n",
            "[430] train acc:100.00, validation acc:10.70\n",
            "[430] train acc:100.00, validation acc:10.80\n",
            "[430] train acc:100.00, validation acc:10.70\n",
            "[430] train acc:100.00, validation acc:10.90\n",
            "[440] train acc:100.00, validation acc:10.30\n",
            "[440] train acc:100.00, validation acc:10.80\n",
            "[440] train acc:100.00, validation acc:10.80\n",
            "[440] train acc:100.00, validation acc:11.70\n",
            "[440] train acc:100.00, validation acc:10.30\n",
            "[440] train acc:100.00, validation acc:10.70\n",
            "[440] train acc:100.00, validation acc:10.70\n",
            "[440] train acc:100.00, validation acc:10.90\n",
            "[450] train acc:100.00, validation acc:10.20\n",
            "[450] train acc:100.00, validation acc:10.20\n",
            "[450] train acc:100.00, validation acc:11.10\n",
            "[450] train acc:100.00, validation acc:11.10\n",
            "[450] train acc:100.00, validation acc:11.10\n",
            "[450] train acc:100.00, validation acc:10.10\n",
            "[450] train acc:100.00, validation acc:10.00\n",
            "[450] train acc:100.00, validation acc:10.00\n",
            "[460] train acc:100.00, validation acc:10.30\n",
            "[460] train acc:100.00, validation acc:10.20\n",
            "[460] train acc:100.00, validation acc:10.30\n",
            "[460] train acc:100.00, validation acc:10.90\n",
            "[460] train acc:100.00, validation acc:11.00\n",
            "[460] train acc:100.00, validation acc:11.00\n",
            "[460] train acc:100.00, validation acc:10.90\n",
            "[460] train acc:100.00, validation acc:10.20\n",
            "[470] train acc:100.00, validation acc:11.00\n",
            "[470] train acc:100.00, validation acc:11.00\n",
            "[470] train acc:100.00, validation acc:11.00\n",
            "[470] train acc:100.00, validation acc:10.50\n",
            "[470] train acc:100.00, validation acc:10.60\n",
            "[470] train acc:100.00, validation acc:10.30\n",
            "[470] train acc:100.00, validation acc:10.30\n",
            "[470] train acc:100.00, validation acc:10.30\n",
            "[480] train acc:100.00, validation acc:11.00\n",
            "[480] train acc:100.00, validation acc:10.40\n",
            "[480] train acc:100.00, validation acc:10.40\n",
            "[480] train acc:100.00, validation acc:10.50\n",
            "[480] train acc:100.00, validation acc:10.50\n",
            "[480] train acc:100.00, validation acc:10.80\n",
            "[480] train acc:100.00, validation acc:11.10\n",
            "[480] train acc:100.00, validation acc:11.20\n",
            "[490] train acc:100.00, validation acc:10.40\n",
            "[490] train acc:100.00, validation acc:10.60\n",
            "[490] train acc:100.00, validation acc:10.60\n",
            "[490] train acc:100.00, validation acc:10.60\n",
            "[490] train acc:100.00, validation acc:10.60\n",
            "[490] train acc:100.00, validation acc:10.60\n",
            "[490] train acc:100.00, validation acc:10.30\n",
            "[490] train acc:100.00, validation acc:10.30\n",
            "[500] train acc:100.00, validation acc:9.80\n",
            "[500] train acc:100.00, validation acc:10.60\n",
            "[500] train acc:100.00, validation acc:10.70\n",
            "[500] train acc:100.00, validation acc:10.60\n",
            "[500] train acc:100.00, validation acc:10.30\n",
            "[500] train acc:100.00, validation acc:10.40\n",
            "[500] train acc:100.00, validation acc:11.20\n",
            "[500] train acc:100.00, validation acc:11.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 준지도 학습2 성능 평가\n",
        "# 평가 정확도가 기준 대비 0% 증가한 73.8%이다.(기준 73.8%)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/deeplearning/models/cifar_model_for_pseudo_label2.pth'))\n",
        "accuracy(testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT04sMTwQucc",
        "outputId": "c6747030-f9ed-4412-c7ad-01bb29d1ef80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73.8"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    }
  ]
}